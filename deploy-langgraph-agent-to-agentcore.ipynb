{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Deploying LangGraph ReAct Agent to AWS Bedrock AgentCore\n",
    "\n",
    "This notebook demonstrates how to deploy a LangGraph ReAct agent to AWS Bedrock AgentCore using direct boto3 API calls. It also enables you to visualize the agent's decision-making process in the GenAI Observability dashboard in Amazon CloudWatch.\n",
    "\n",
    "LangGraph is a library for building stateful, multi-actor applications with LLMs using graphs. It's particularly well-suited for implementing ReAct (Reasoning and Acting) style agents that can reason about a problem and take actions to solve it.\n",
    "\n",
    "To can access the Amazon Bedrock AgentCore Developer Guide, check out the [AWS documentation](https://docs.aws.amazon.com/bedrock-agentcore/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.12 or later\n",
    "- boto3 1.39 or later\n",
    "- AWS CLI installed and configured with appropriate permissions\n",
    "\n",
    "In addition, you should have the following readily available:\n",
    "- Amazon S3 bucket to package code\n",
    "- AWS IAM role for automation access\n",
    "- Knowledge bases are fully synched\n",
    "- External functions for enterprise systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install required packages\n",
    "\n",
    "Ensure you have the latest versions required installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import required libraries\n",
    "\n",
    "Import all necessary Python libraries for AWS interactions and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to automatically open the SSO authorization page in your default browser.\n",
      "If the browser does not open, open the following URL:\n",
      "\n",
      "https://oidc.us-east-1.amazonaws.com/authorize?response_type=code&client_id=5HFSsfzb_H2rFv2ZjBPM_nVzLWVhc3QtMQ&redirect_uri=http%3A%2F%2F127.0.0.1%3A50027%2Foauth%2Fcallback&state=3773008d-72f4-4cf4-87cb-4ad23e83bef2&code_challenge_method=S256&scopes=sso%3Aaccount%3Aaccess&code_challenge=aDI4ZmNFgIE30_4xPJj95YXyMPTGTgeHk1lzUg-92KA\n",
      "Successfully logged into Start URL: https://d-9067a83728.awsapps.com/start/#\n"
     ]
    }
   ],
   "source": [
    "!aws sso login --profile bedrock-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport re\nimport sys\nimport json\nimport time\nimport uuid\nimport string\nimport random\nimport zipfile\nimport tempfile\nimport collections\nimport boto3\nimport subprocess\nimport botocore\nfrom pathlib import Path\n\n # Set AWS Profile for the entire notebook\nos.environ['AWS_PROFILE'] = 'bedrock-demo'\nos.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n\n# Get AWS credentials from CLI (works with SSO)\ndef get_aws_credentials():\n    \"\"\"Get AWS credentials from CLI that work with SSO\"\"\"\n    try:\n        # Get credentials using AWS CLI\n        result = subprocess.run(\n            ['aws', 'sts', 'get-caller-identity', '--profile', 'bedrock-demo'],\n            capture_output=True, text=True, check=True\n        )\n        identity = json.loads(result.stdout)\n\n        # Get session token\n        creds_result = subprocess.run(\n            ['aws', 'configure', 'export-credentials', '--profile', 'bedrock-demo'],\n            capture_output=True, text=True, check=True\n        )\n        creds = json.loads(creds_result.stdout)\n\n        # Set environment variables\n        os.environ['AWS_ACCESS_KEY_ID'] = creds['AccessKeyId']\n        os.environ['AWS_SECRET_ACCESS_KEY'] = creds['SecretAccessKey']\n        os.environ['AWS_SESSION_TOKEN'] = creds['SessionToken']\n        os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n\n        print(f\"✅ AWS Credentials configured from SSO\")\n        print(f\"   Account: <YOUR_ACCOUNT_ID>\")\n        print(f\"   User: <YOUR_USER>\")\n\n        # Configure boto3 default session\n        boto3.setup_default_session(\n            aws_access_key_id=creds['AccessKeyId'],\n            aws_secret_access_key=creds['SecretAccessKey'],\n            aws_session_token=creds['SessionToken'],\n            region_name='us-east-1'\n        )\n\n        return True\n\n    except subprocess.CalledProcessError as e:\n        print(f\"❌ Failed to get AWS credentials: {e}\")\n        print(\"\\nPlease run: aws sso login --profile bedrock-demo\")\n        return False\n    except Exception as e:\n        print(f\"❌ Error setting up credentials: {e}\")\n        return False\n\n# Get AWS credentials\nif not get_aws_credentials():\n    print(\"\\n⚠️ Please login to AWS SSO and restart the kernel\")\nelse:\n    print(\"\\n✅ Ready to proceed with the notebook\")\n\n# LaunchDarkly imports for configuration management\nimport ldclient\nfrom ldclient import Context\nfrom ldclient.config import Config as LDConfig\nfrom ldai.client import LDAIClient"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set required parameters\n",
    "\n",
    "Update the parameters below using your environment specific details. These parameters will be used throughout the notebook for creating and configuring the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LaunchDarkly Configuration\nLAUNCHDARKLY_SDK_KEY = os.getenv('LAUNCHDARKLY_SDK_KEY', '<provide LaunchDarkly SDK Key>')\nLAUNCHDARKLY_AGENT_KEY = os.getenv('LAUNCHDARKLY_AGENT_KEY', 'pet-store-agent')\n\n# AWS Configuration (can be overridden by LaunchDarkly)\n# These should be set in your .env file:\n# AWS_ACCOUNT_ID=your-account-id\n# AGENTCORE_ROLE_NAME=your-role-name\n# BUILD_BUCKET_NAME=your-bucket-name\n\nAWS_ACCOUNT_ID = os.getenv('AWS_ACCOUNT_ID', '<YOUR_ACCOUNT_ID>')\nAGENTCORE_ROLE_NAME = os.getenv('AGENTCORE_ROLE_NAME', 'PetStoreAgentCoreExecutionRole')\nBUILD_BUCKET_NAME = os.getenv('BUILD_BUCKET_NAME', 'petstore-build')\n\n# Construct ARNs from environment variables\nSolutionAccessRoleArn = f'arn:aws:iam::{AWS_ACCOUNT_ID}:role/{AGENTCORE_ROLE_NAME}'\nCodeBucketForAutomationARN = f'arn:aws:s3:::{BUILD_BUCKET_NAME}'\nAgent_Directory_Name = '.'\n\n# LlamaIndex Configuration (will be pulled from LaunchDarkly)\nLLAMAINDEX_STORAGE_DIR = './storage'  # Default, will be overridden by LaunchDarkly\nLLAMAINDEX_DATA_DIR = './data'        # Default, will be overridden by LaunchDarkly\n\nprint(f\"LaunchDarkly Agent Key: {LAUNCHDARKLY_AGENT_KEY}\")\nprint(f\"AWS Account ID: {'***' + AWS_ACCOUNT_ID[-4:] if len(AWS_ACCOUNT_ID) > 4 else '***'}\")\nprint(f\"Role: {AGENTCORE_ROLE_NAME}\")\nprint(f\"Bucket: {BUILD_BUCKET_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize LaunchDarkly and Fetch Configuration\n",
    "\n",
    "Initialize the LaunchDarkly client and fetch the agent configuration dynamically. This replaces hardcoded values with feature flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully fetched configuration from LaunchDarkly\n",
      "   Model: amazon.nova-pro-v1:0 (Bedrock)\n",
      "   AWS Region: us-east-1\n",
      "   LlamaIndex Storage: ./storage\n",
      "   Enabled Tools: retrieve_product_info, get_inventory, retrieve_pet_care, get_user_by_email, get_user_by_id\n"
     ]
    }
   ],
   "source": [
    "def fetch_launchdarkly_config():\n",
    "    \"\"\"\n",
    "    Fetch configuration from LaunchDarkly for the pet store agent.\n",
    "    Returns a dictionary with all necessary configuration values.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    \n",
    "    try:\n",
    "        # Initialize LaunchDarkly client\n",
    "        ldclient.set_config(LDConfig(LAUNCHDARKLY_SDK_KEY))\n",
    "        ld_client = ldclient.get()\n",
    "        \n",
    "        if not ld_client.is_initialized():\n",
    "            print(\"⚠️ Warning: LaunchDarkly client failed to initialize. Using defaults.\")\n",
    "            return config\n",
    "        \n",
    "        # Create AI client wrapper\n",
    "        ai_client = LDAIClient(ld_client)\n",
    "        \n",
    "        # Build context for configuration retrieval\n",
    "        context = Context.builder(\"deployment-context\").build()\n",
    "        \n",
    "        # Get agent configuration\n",
    "        from ldai.client import AIAgentConfigDefault, ModelConfig, ProviderConfig\n",
    "        \n",
    "        default_agent = AIAgentConfigDefault(\n",
    "            enabled=False,\n",
    "            model=ModelConfig(\"ERROR_MODEL_NOT_CONFIGURED\"),\n",
    "            provider=ProviderConfig(\"ERROR_PROVIDER_NOT_CONFIGURED\"),\n",
    "            instructions=\"ERROR: LaunchDarkly AI Config not found or disabled.\",\n",
    "        )\n",
    "        \n",
    "        agent_config = ai_client.agent_config(\n",
    "            LAUNCHDARKLY_AGENT_KEY,\n",
    "            context,\n",
    "            default_value=default_agent,\n",
    "            variables={}\n",
    "        )\n",
    "        \n",
    "        # Convert to dict to access nested values\n",
    "        agent_dict = agent_config.to_dict() if hasattr(agent_config, 'to_dict') else {}\n",
    "        \n",
    "        # Extract configuration from agent config\n",
    "        model_config = agent_dict.get(\"model\", {})\n",
    "        parameters = model_config.get(\"parameters\", {})\n",
    "        custom = model_config.get(\"custom\", {})\n",
    "        \n",
    "        # Extract tool configurations to get Lambda function names\n",
    "        tools = parameters.get(\"tools\", [])\n",
    "        lambda_functions = {}\n",
    "        \n",
    "        for tool in tools:\n",
    "            if isinstance(tool, dict):\n",
    "                tool_name = tool.get(\"name\", \"\")\n",
    "                tool_custom = tool.get(\"custom\", {})\n",
    "                \n",
    "                # Extract Lambda function names from tool configs\n",
    "                if \"get_inventory\" in tool_name:\n",
    "                    lambda_functions[\"inventory_lambda\"] = tool_custom.get(\"lambda_function_name\", \n",
    "                                                                            \"team-PetStoreInventoryManagementFunction\")\n",
    "                elif \"get_user\" in tool_name:\n",
    "                    lambda_functions[\"user_lambda\"] = tool_custom.get(\"lambda_function_name\", \n",
    "                                                                      \"team-PetStoreUserManagementFunction\")\n",
    "        \n",
    "        # Build configuration dictionary\n",
    "        config = {\n",
    "            \"aws_region\": custom.get(\"aws_region\", os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\")),\n",
    "            \"lambda_functions\": lambda_functions,\n",
    "            \"llamaindex\": {\n",
    "                \"storage_dir\": custom.get(\"llamaindex\", {}).get(\"storage_dir\", LLAMAINDEX_STORAGE_DIR),\n",
    "                \"data_dir\": custom.get(\"llamaindex\", {}).get(\"data_dir\", LLAMAINDEX_DATA_DIR),\n",
    "                \"chunk_size\": custom.get(\"llamaindex\", {}).get(\"chunk_size\", 1024),\n",
    "                \"chunk_overlap\": custom.get(\"llamaindex\", {}).get(\"chunk_overlap\", 200),\n",
    "                \"similarity_top_k\": custom.get(\"llamaindex\", {}).get(\"similarity_top_k\", 5)\n",
    "            },\n",
    "            \"model\": {\n",
    "                \"name\": agent_config.model.name,\n",
    "                \"provider\": agent_config.provider.name,\n",
    "                \"temperature\": parameters.get(\"temperature\", 0.7),\n",
    "                \"max_tokens\": parameters.get(\"max_tokens\", 4096)\n",
    "            },\n",
    "            \"tools_enabled\": [tool.get(\"name\") for tool in tools if isinstance(tool, dict) and tool.get(\"name\")]\n",
    "        }\n",
    "        \n",
    "        print(\"✅ Successfully fetched configuration from LaunchDarkly\")\n",
    "        print(f\"   Model: {config['model']['name']} ({config['model']['provider']})\")\n",
    "        print(f\"   AWS Region: {config['aws_region']}\")\n",
    "        print(f\"   LlamaIndex Storage: {config['llamaindex']['storage_dir']}\")\n",
    "        print(f\"   Enabled Tools: {', '.join(config['tools_enabled'])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching LaunchDarkly config: {str(e)}\")\n",
    "        print(\"Using default configuration values\")\n",
    "        \n",
    "        # Default configuration as fallback\n",
    "        config = {\n",
    "            \"aws_region\": os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-1\"),\n",
    "            \"lambda_functions\": {},\n",
    "            \"llamaindex\": {\n",
    "                \"storage_dir\": LLAMAINDEX_STORAGE_DIR,\n",
    "                \"data_dir\": LLAMAINDEX_DATA_DIR,\n",
    "                \"chunk_size\": 1024,\n",
    "                \"chunk_overlap\": 200,\n",
    "                \"similarity_top_k\": 5\n",
    "            },\n",
    "            \"model\": {\n",
    "                \"name\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "                \"provider\": \"bedrock\",\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": 4096\n",
    "            },\n",
    "            \"tools_enabled\": [\"retrieve_product_info\", \"retrieve_pet_care\", \"get_inventory\", \n",
    "                             \"get_user_by_email\", \"get_user_by_id\"]\n",
    "        }\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Fetch configuration from LaunchDarkly\n",
    "agent_config = fetch_launchdarkly_config()\n",
    "\n",
    "# Extract key values for use in the notebook\n",
    "aws_region = agent_config.get(\"aws_region\", \"us-east-1\")\n",
    "llamaindex_config = agent_config.get(\"llamaindex\", {})\n",
    "lambda_functions = agent_config.get(\"lambda_functions\", {})\n",
    "tools_enabled = agent_config.get(\"tools_enabled\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Verify agent code requirements\n",
    "\n",
    "We'll check that necessary files for the agent exist in the expected locations before proceeding with the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentCore entrypoint found at agentcore_entrypoint.py\n",
      "Requirements file found at requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Verify AgentCore entrypoint exists\n",
    "agentcore_entrypoint_file = Path(f\"{Agent_Directory_Name}/agentcore_entrypoint.py\")\n",
    "if agentcore_entrypoint_file.exists():\n",
    "    print(f\"AgentCore entrypoint found at {agentcore_entrypoint_file}\")\n",
    "else:\n",
    "    print(f\"AgentCore entrypoint not found at {agentcore_entrypoint_file}\")\n",
    "\n",
    "# Verify requirements file exists\n",
    "requirements_file = Path(f\"{Agent_Directory_Name}/requirements.txt\")\n",
    "if requirements_file.exists():\n",
    "    print(f\"Requirements file found at {requirements_file}\")\n",
    "else:\n",
    "    print(f\"Requirements file not found at {requirements_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Create Dockerfile for Agent\n",
    "\n",
    "We need to create a Dockerfile to package the agent for deployment to AgentCore Runtime. This Dockerfile will include all necessary dependencies and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile created at Dockerfile\n"
     ]
    }
   ],
   "source": [
    "def create_dockerfile():\n",
    "    '''Create a Dockerfile for AgentCore Runtime with LaunchDarkly and LlamaIndex support'''\n",
    "    dockerfile_content = f'''\n",
    "FROM --platform=linux/arm64 public.ecr.aws/docker/library/python:3.12-slim-bookworm\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements and install dependencies\n",
    "COPY {Agent_Directory_Name}/requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "RUN pip install bedrock-agentcore\n",
    "RUN pip install aws-opentelemetry-distro\n",
    "\n",
    "# Copy agent code and tools\n",
    "COPY {Agent_Directory_Name}/*.py ./\n",
    "\n",
    "# Copy LlamaIndex storage directory if it exists\n",
    "COPY {Agent_Directory_Name}/storage ./storage\n",
    "COPY {Agent_Directory_Name}/data ./data\n",
    "\n",
    "# Set default AWS region\n",
    "ENV AWS_DEFAULT_REGION=${{AWS_DEFAULT_REGION}}\n",
    "\n",
    "# LaunchDarkly Configuration\n",
    "ENV LAUNCHDARKLY_SDK_KEY=${{LAUNCHDARKLY_SDK_KEY}}\n",
    "ENV LAUNCHDARKLY_AGENT_KEY=${{LAUNCHDARKLY_AGENT_KEY}}\n",
    "\n",
    "# LlamaIndex Configuration\n",
    "ENV LLAMAINDEX_STORAGE_DIR=${{LLAMAINDEX_STORAGE_DIR}}\n",
    "ENV LLAMAINDEX_DATA_DIR=${{LLAMAINDEX_DATA_DIR}}\n",
    "\n",
    "# Optional Lambda Function Names (can be overridden by LaunchDarkly at runtime)\n",
    "ENV INVENTORY_LAMBDA=${{INVENTORY_LAMBDA}}\n",
    "ENV USER_LAMBDA=${{USER_LAMBDA}}\n",
    "\n",
    "# Enable fallback tools for local testing\n",
    "ENV ENABLE_FALLBACK_TOOLS=${{ENABLE_FALLBACK_TOOLS}}\n",
    "\n",
    "# OpenTelemetry Configuration for AWS CloudWatch GenAI Observability\n",
    "ENV OTEL_PYTHON_DISTRO=aws_distro\n",
    "ENV OTEL_PYTHON_CONFIGURATOR=aws_configurator\n",
    "ENV OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n",
    "ENV OTEL_TRACES_EXPORTER=otlp\n",
    "ENV OTEL_EXPORTER_OTLP_LOGS_HEADERS=x-aws-log-group=agents/langgraph-agent-logs,x-aws-log-stream=default,x-aws-metric-namespace=agents\n",
    "ENV OTEL_RESOURCE_ATTRIBUTES=service.name=langgraph-agent\n",
    "ENV AGENT_OBSERVABILITY_ENABLED=true\n",
    "\n",
    "# Expose the port that AgentCore Runtime expects\n",
    "EXPOSE 8080\n",
    "\n",
    "# Run the agent\n",
    "CMD [\"opentelemetry-instrument\", \"python\", \"agentcore_entrypoint.py\"]\n",
    "'''\n",
    "    \n",
    "    # Write the Dockerfile\n",
    "    dockerfile_path = Path(\"Dockerfile\")\n",
    "    with open(dockerfile_path, 'w') as f:\n",
    "        f.write(dockerfile_content)\n",
    "    \n",
    "    return dockerfile_path\n",
    "\n",
    "# Create the Dockerfile\n",
    "dockerfile_path = create_dockerfile()\n",
    "print(f\"Dockerfile created at {dockerfile_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build Docker image using SageMaker Docker Build CLI\n",
    "\n",
    "Use the SageMaker Docker Build CLI to build and push our Docker image to Amazon ECR. This tool handles the Docker build process in the background using AWS CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Build functions defined successfully - using external buildspec file\n"
     ]
    }
   ],
   "source": [
    "# Define required functions for building arm64 container image\n",
    "\n",
    "Position = collections.namedtuple(\"Position\", [\"timestamp\", \"skip\"])\n",
    "\n",
    "def _log_stream(client, log_group, stream_name, position):\n",
    "    start_time, skip = position\n",
    "    next_token = None\n",
    "    event_count = 1\n",
    "    while event_count > 0:\n",
    "        token_arg = {\"nextToken\": next_token} if next_token else {}\n",
    "        response = client.get_log_events(\n",
    "            logGroupName=log_group, logStreamName=stream_name,\n",
    "            startTime=start_time, startFromHead=True, **token_arg\n",
    "        )\n",
    "        next_token = response[\"nextForwardToken\"]\n",
    "        events = response[\"events\"]\n",
    "        event_count = len(events)\n",
    "        if event_count > skip:\n",
    "            events = events[skip:]\n",
    "            skip = 0\n",
    "        else:\n",
    "            skip = skip - event_count\n",
    "            events = []\n",
    "        for ev in events:\n",
    "            ts, count = position\n",
    "            if ev[\"timestamp\"] == ts:\n",
    "                position = Position(timestamp=ts, skip=count + 1)\n",
    "            else:\n",
    "                position = Position(timestamp=ev[\"timestamp\"], skip=1)\n",
    "            yield ev, position\n",
    "\n",
    "def _logs_for_build(build_id, session, wait=False, poll=10):\n",
    "    codebuild = session.client(\"codebuild\")\n",
    "    description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "    status = description[\"buildStatus\"]\n",
    "    log_group = description[\"logs\"].get(\"groupName\")\n",
    "    stream_name = description[\"logs\"].get(\"streamName\")\n",
    "    position = Position(timestamp=0, skip=0)\n",
    "    config = botocore.config.Config(retries={\"max_attempts\": 15})\n",
    "    client = session.client(\"logs\", config=config)\n",
    "\n",
    "    while log_group is None and status == \"IN_PROGRESS\":\n",
    "        time.sleep(poll)\n",
    "        description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "        log_group = description[\"logs\"].get(\"groupName\")\n",
    "        stream_name = description[\"logs\"].get(\"streamName\")\n",
    "        status = description[\"buildStatus\"]\n",
    "\n",
    "    last_describe_job_call = time.time()\n",
    "    dot_printed = False\n",
    "    dot = True\n",
    "\n",
    "    while True:\n",
    "        for event, position in _log_stream(client, log_group, stream_name, position):\n",
    "            print(event[\"message\"].rstrip())\n",
    "            if dot:\n",
    "                dot = False\n",
    "                if dot_printed:\n",
    "                    print()\n",
    "\n",
    "        if not wait or status != \"IN_PROGRESS\":\n",
    "            break\n",
    "\n",
    "        time.sleep(poll)\n",
    "        if dot:\n",
    "            print(\".\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            dot_printed = True\n",
    "\n",
    "        if time.time() - last_describe_job_call >= 30:\n",
    "            description = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "            status = description[\"buildStatus\"]\n",
    "            last_describe_job_call = time.time()\n",
    "            if status != \"IN_PROGRESS\":\n",
    "                print()\n",
    "                break\n",
    "\n",
    "def build_arm64_image(role, bucket, repository_name, verbose=False):\n",
    "    # Use default session (which now has credentials from environment)\n",
    "    session = boto3.Session()\n",
    "    account_id = session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "    region = session.region_name or 'us-east-1'\n",
    "\n",
    "    # Upload source code\n",
    "    random_suffix = \"\".join(random.choices(string.ascii_letters, k=16))\n",
    "    key = f\"codebuild-{random_suffix}.zip\"\n",
    "\n",
    "    with tempfile.TemporaryFile() as tmp:\n",
    "        with zipfile.ZipFile(tmp, \"w\") as zip:\n",
    "            for dirname, _, filelist in os.walk(\".\"):\n",
    "                # Skip hidden directories and __pycache__\n",
    "                if '/.git' in dirname or '__pycache__' in dirname or '.ipynb_checkpoints' in dirname:\n",
    "                    continue\n",
    "                for file in filelist:\n",
    "                    # Skip hidden files and checkpoints\n",
    "                    if not file.startswith('.'):\n",
    "                        zip.write(f\"{dirname}/{file}\")\n",
    "\n",
    "            # Read the buildspec from the test file we created\n",
    "            with open('test_buildspec.yml', 'r') as f:\n",
    "                buildspec_content = f.read()\n",
    "\n",
    "            # Write buildspec to zip\n",
    "            zip.writestr(\"buildspec.yml\", buildspec_content)\n",
    "\n",
    "        tmp.seek(0)\n",
    "        session.client(\"s3\").upload_fileobj(tmp, bucket, key)\n",
    "\n",
    "    # Create ECR repo\n",
    "    try:\n",
    "        session.client(\"ecr\").create_repository(repositoryName=repository_name)\n",
    "        print(f\"Created ECR repository {repository_name}\")\n",
    "    except:\n",
    "        print(f\"ECR repository {repository_name} already exists\")\n",
    "\n",
    "    # Create and run CodeBuild project\n",
    "    project_name = f\"build-{random_suffix}\"\n",
    "    codebuild = session.client(\"codebuild\")\n",
    "\n",
    "    codebuild.create_project(\n",
    "        name=project_name,\n",
    "        source={\"type\": \"S3\", \"location\": f\"{bucket}/{key}\"},\n",
    "        artifacts={\"type\": \"NO_ARTIFACTS\"},\n",
    "        environment={\n",
    "            \"type\": \"ARM_CONTAINER\",\n",
    "            \"image\": \"aws/codebuild/amazonlinux2-aarch64-standard:3.0\",\n",
    "            \"computeType\": \"BUILD_GENERAL1_SMALL\",\n",
    "            \"environmentVariables\": [\n",
    "                {\"name\": \"AWS_DEFAULT_REGION\", \"value\": region},\n",
    "                {\"name\": \"AWS_ACCOUNT_ID\", \"value\": account_id},\n",
    "                {\"name\": \"IMAGE_REPO_NAME\", \"value\": repository_name},\n",
    "                {\"name\": \"IMAGE_TAG\", \"value\": \"latest\"},\n",
    "            ],\n",
    "            \"privilegedMode\": True,\n",
    "        },\n",
    "        serviceRole=f\"arn:aws:iam::{account_id}:role/{role}\",\n",
    "    )\n",
    "\n",
    "    build_id = codebuild.start_build(projectName=project_name)[\"build\"][\"id\"]\n",
    "    print(f\"Starting build {build_id} with verbose={verbose}\")\n",
    "\n",
    "    if verbose:\n",
    "        # Stream logs using library implementation\n",
    "        _logs_for_build(build_id, session, wait=True)\n",
    "    else:\n",
    "        # Just wait for completion without streaming logs\n",
    "        while True:\n",
    "            build_info = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "            status = build_info[\"buildStatus\"]\n",
    "            if status != \"IN_PROGRESS\":\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(30)\n",
    "        print()\n",
    "\n",
    "    # Get final status\n",
    "    build_info = codebuild.batch_get_builds(ids=[build_id])[\"builds\"][0]\n",
    "    status = build_info[\"buildStatus\"]\n",
    "    print(f\"Build complete, status = {status}\")\n",
    "\n",
    "    # Cleanup\n",
    "    codebuild.delete_project(name=project_name)\n",
    "    session.client(\"s3\").delete_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    if status == \"SUCCEEDED\":\n",
    "        ecr_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:latest\"\n",
    "        print(f\"Image URI: {ecr_uri}\")\n",
    "        return ecr_uri\n",
    "    else:\n",
    "        raise Exception(f\"Build failed with status: {status}\")\n",
    "\n",
    "print(\"✅ Build functions defined successfully - using external buildspec file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Configuration:\n",
      "  AWS Profile: bedrock-demo\n",
      "  Solution Role: arn:aws:iam::955116512041:role/PetStoreAgentCoreExecutionRole\n",
      "  S3 Bucket: arn:aws:s3:::petstore-build\n",
      "  Role Name: PetStoreAgentCoreExecutionRole\n",
      "  Bucket Name: petstore-build\n",
      "  ECR Repository: langgraph-agent-repo\n",
      "\n",
      "ECR repository langgraph-agent-repo already exists\n",
      "Starting build build-DRkFeMDEilQeMhkK:dc79adfa-0467-4d9e-8976-695885663a03 with verbose=True\n",
      ".[Container] 2026/01/14 04:35:52.264918 Running on CodeBuild On-demand\n",
      "\n",
      "[Container] 2026/01/14 04:35:52.264995 Waiting for agent ping\n",
      "[Container] 2026/01/14 04:35:52.365896 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2026/01/14 04:35:53.955142 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2026/01/14 04:35:53.956095 CODEBUILD_SRC_DIR=/codebuild/output/src2889961814/src\n",
      "[Container] 2026/01/14 04:35:53.956533 YAML location is /codebuild/output/src2889961814/src/buildspec.yml\n",
      "[Container] 2026/01/14 04:35:53.958414 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2026/01/14 04:35:53.958498 Processing environment variables\n",
      "[Container] 2026/01/14 04:35:54.065592 No runtime version selected in buildspec.\n",
      "[Container] 2026/01/14 04:35:54.096599 Moving to directory /codebuild/output/src2889961814/src\n",
      "[Container] 2026/01/14 04:35:54.096671 Cache is not defined in the buildspec\n",
      "[Container] 2026/01/14 04:35:54.136051 Skip cache due to: no paths specified to be cached\n",
      "[Container] 2026/01/14 04:35:54.136386 Registering with agent\n",
      "[Container] 2026/01/14 04:35:54.173184 Phases found in YAML: 3\n",
      "[Container] 2026/01/14 04:35:54.173212  PRE_BUILD: 9 commands\n",
      "[Container] 2026/01/14 04:35:54.173215  BUILD: 4 commands\n",
      "[Container] 2026/01/14 04:35:54.173218  POST_BUILD: 3 commands\n",
      "[Container] 2026/01/14 04:35:54.173425 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2026/01/14 04:35:54.173435 Phase context status code:  Message:\n",
      "[Container] 2026/01/14 04:35:54.276641 Entering phase INSTALL\n",
      "[Container] 2026/01/14 04:35:54.310442 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2026/01/14 04:35:54.310463 Phase context status code:  Message:\n",
      "[Container] 2026/01/14 04:35:54.382318 Entering phase PRE_BUILD\n",
      "[Container] 2026/01/14 04:35:54.416207 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2026/01/14 04:35:54.422422 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:02.305271 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 763104351884.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:03.010492 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 217643126080.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:03.731512 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 727897471807.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:04.431334 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 626614931356.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:05.118383 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 683313688378.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:05.840570 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 520713654638.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:06.551801 Running command aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin 462105765813.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\n",
      "\n",
      "WARNING! Your credentials are stored unencrypted in '/root/.docker/config.json'.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/go/credential-store/\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2026/01/14 04:36:07.229964 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2026/01/14 04:36:07.229982 Phase context status code:  Message:\n",
      "[Container] 2026/01/14 04:36:07.267603 Entering phase BUILD\n",
      "[Container] 2026/01/14 04:36:07.271086 Running command echo Build started on `date`\n",
      "Build started on Wed Jan 14 04:36:07 UTC 2026\n",
      "\n",
      "[Container] 2026/01/14 04:36:07.287043 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2026/01/14 04:36:07.292895 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 1.66kB done\n",
      "#1 WARN: FromPlatformFlagConstDisallowed: FROM --platform flag should not use constant value \"linux/arm64\" (line 2)\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for public.ecr.aws/docker/library/python:3.12-slim-bookworm\n",
      "#2 DONE 0.3s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 transferring context: 617.24kB 0.0s done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [1/9] FROM public.ecr.aws/docker/library/python:3.12-slim-bookworm@sha256:4a3ceab05b4e396df42a042415e43a286bb5793352b9258f889d6c7d38ed01fb\n",
      "#5 resolve public.ecr.aws/docker/library/python:3.12-slim-bookworm@sha256:4a3ceab05b4e396df42a042415e43a286bb5793352b9258f889d6c7d38ed01fb done\n",
      "#5 sha256:33bdc9671af8942d96d2f78f67aeec06580065dde1272decac3732689ec7c0e8 13.63MB / 28.11MB 0.1s\n",
      "#5 sha256:4ae0f19ca418b0a15b934de535e88f8e25eba7518487f50d48b2ce849462ce86 0B / 3.35MB 0.1s\n",
      "#5 sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 0B / 13.60MB 0.1s\n",
      "#5 sha256:4a3ceab05b4e396df42a042415e43a286bb5793352b9258f889d6c7d38ed01fb 9.13kB / 9.13kB done\n",
      "#5 sha256:7baba4d626b357f4b641f242a8d32f5d0e7bfc12926d54e72411eb8738325003 1.75kB / 1.75kB done\n",
      "#5 sha256:c50afa1c356bb98625d0a402dfbc1a83c09d99f273473d7823962b313f16d10f 5.71kB / 5.71kB done\n",
      "#5 sha256:33bdc9671af8942d96d2f78f67aeec06580065dde1272decac3732689ec7c0e8 28.11MB / 28.11MB 0.2s done\n",
      "#5 sha256:4ae0f19ca418b0a15b934de535e88f8e25eba7518487f50d48b2ce849462ce86 3.35MB / 3.35MB 0.3s done\n",
      "#5 sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 4.19MB / 13.60MB 0.3s\n",
      "#5 sha256:b81775473d6e9d5b65febaa97ae4628da4eaacc135f3345a9d56adf631fda9e3 250B / 250B 0.3s done\n",
      "#5 extracting sha256:33bdc9671af8942d96d2f78f67aeec06580065dde1272decac3732689ec7c0e8 0.1s\n",
      "#5 sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 9.44MB / 13.60MB 0.5s\n",
      "#5 sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 12.58MB / 13.60MB 0.6s\n",
      "#5 sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 13.60MB / 13.60MB 0.8s done\n",
      "#5 extracting sha256:33bdc9671af8942d96d2f78f67aeec06580065dde1272decac3732689ec7c0e8 0.9s done\n",
      "#5 extracting sha256:4ae0f19ca418b0a15b934de535e88f8e25eba7518487f50d48b2ce849462ce86 0.1s done\n",
      "#5 extracting sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 0.1s\n",
      "#5 extracting sha256:c3658e52572d4d43a2e57dd875bd5b19c5c713ddc1eeff8c94b05145a5573f1d 0.5s done\n",
      "#5 extracting sha256:b81775473d6e9d5b65febaa97ae4628da4eaacc135f3345a9d56adf631fda9e3 done\n",
      "#5 DONE 1.9s\n",
      "\n",
      "#6 [2/9] WORKDIR /app\n",
      "#6 DONE 1.1s\n",
      "\n",
      "#7 [3/9] COPY ./requirements.txt .\n",
      "#7 DONE 0.1s\n",
      "\n",
      "#8 [4/9] RUN pip install --no-cache-dir -r requirements.txt\n",
      "#8 2.041 Collecting boto3>=1.34.0 (from -r requirements.txt (line 2))\n",
      "#8 2.084   Downloading boto3-1.42.27-py3-none-any.whl.metadata (6.8 kB)\n",
      "#8 2.358 Collecting botocore>=1.34.0 (from -r requirements.txt (line 3))\n",
      "#8 2.361   Downloading botocore-1.42.27-py3-none-any.whl.metadata (5.9 kB)\n",
      "#8 2.375 Collecting launchdarkly-server-sdk>=9.0.0 (from -r requirements.txt (line 6))\n",
      "#8 2.379   Downloading launchdarkly_server_sdk-9.14.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "#8 2.388 Collecting launchdarkly-server-sdk-ai-langchain>=0.1.0 (from -r requirements.txt (line 7))\n",
      "#8 2.393   Downloading launchdarkly_server_sdk_ai_langchain-0.3.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "#8 2.453 Collecting langchain>=0.1.0 (from -r requirements.txt (line 10))\n",
      "#8 2.456   Downloading langchain-1.2.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "#8 2.500 Collecting langchain-core>=0.1.0 (from -r requirements.txt (line 11))\n",
      "#8 2.503   Downloading langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 2.518 Collecting langchain-aws>=0.1.0 (from -r requirements.txt (line 12))\n",
      "#8 2.524   Downloading langchain_aws-1.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "#8 2.579 Collecting langgraph>=0.1.0 (from -r requirements.txt (line 13))\n",
      "#8 2.583   Downloading langgraph-1.0.6-py3-none-any.whl.metadata (7.4 kB)\n",
      "#8 2.627 Collecting llama-index-core>=0.10.0 (from -r requirements.txt (line 16))\n",
      "#8 2.631   Downloading llama_index_core-0.14.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "#8 2.647 Collecting llama-index-readers-file>=0.1.0 (from -r requirements.txt (line 17))\n",
      "#8 2.651   Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 2.661 Collecting llama-index-embeddings-bedrock>=0.1.0 (from -r requirements.txt (line 18))\n",
      "#8 2.665   Downloading llama_index_embeddings_bedrock-0.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "#8 2.677 Collecting llama-index-llms-bedrock>=0.1.0 (from -r requirements.txt (line 19))\n",
      "#8 2.691   Downloading llama_index_llms_bedrock-0.4.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 2.771 Collecting pydantic>=2.0.0 (from -r requirements.txt (line 23))\n",
      "#8 2.774   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "#8 2.792 Collecting httpx>=0.24.0 (from -r requirements.txt (line 24))\n",
      "#8 2.795   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "#8 2.808 Collecting typing-extensions>=4.8.0 (from -r requirements.txt (line 25))\n",
      "#8 2.811   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "#8 2.951 Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.34.0->-r requirements.txt (line 2))\n",
      "#8 2.954   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "#8 2.966 Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.34.0->-r requirements.txt (line 2))\n",
      "#8 2.969   Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "#8 2.981 Collecting python-dateutil<3.0.0,>=2.1 (from botocore>=1.34.0->-r requirements.txt (line 3))\n",
      "#8 2.984   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "#8 3.014 Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore>=1.34.0->-r requirements.txt (line 3))\n",
      "#8 3.017   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "#8 3.033 Collecting certifi>=2018.4.16 (from launchdarkly-server-sdk>=9.0.0->-r requirements.txt (line 6))\n",
      "#8 3.036   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "#8 3.042 Collecting expiringdict>=1.1.4 (from launchdarkly-server-sdk>=9.0.0->-r requirements.txt (line 6))\n",
      "#8 3.045   Downloading expiringdict-1.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 3.054 Collecting launchdarkly-eventsource<2.0.0,>=1.5.0 (from launchdarkly-server-sdk>=9.0.0->-r requirements.txt (line 6))\n",
      "#8 3.058   Downloading launchdarkly_eventsource-1.5.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "#8 3.063 Collecting pyRFC3339>=1.0 (from launchdarkly-server-sdk>=9.0.0->-r requirements.txt (line 6))\n",
      "#8 3.071   Downloading pyrfc3339-2.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "#8 3.081 Collecting semver>=2.10.2 (from launchdarkly-server-sdk>=9.0.0->-r requirements.txt (line 6))\n",
      "#8 3.084   Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "#8 3.146 Collecting launchdarkly-server-sdk-ai>=0.12.0 (from launchdarkly-server-sdk-ai-langchain>=0.1.0->-r requirements.txt (line 7))\n",
      "#8 3.152   Downloading launchdarkly_server_sdk_ai-0.12.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "#8 3.204 Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.208   Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "#8 3.264 Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.268   Downloading langsmith-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "#8 3.282 Collecting packaging<26.0.0,>=23.2.0 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.286   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "#8 3.310 Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.316   Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.4 kB)\n",
      "#8 3.330 Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.333   Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "#8 3.369 Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 3.373   Downloading uuid_utils-0.13.0-cp39-abi3-manylinux_2_24_aarch64.whl.metadata (5.4 kB)\n",
      "#8 3.615 Collecting numpy<3,>=2.2 (from langchain-aws>=0.1.0->-r requirements.txt (line 12))\n",
      "#8 3.620   Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (6.6 kB)\n",
      "#8 3.645 Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 3.649   Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "#8 3.659 Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 3.663   Downloading langgraph_prebuilt-1.0.6-py3-none-any.whl.metadata (5.2 kB)\n",
      "#8 3.708 Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 3.711   Downloading langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "#8 3.762 Collecting xxhash>=3.5.0 (from langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 3.766   Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "#8 4.097 Collecting aiohttp<4,>=3.8.6 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.100   Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (8.1 kB)\n",
      "#8 4.109 Collecting aiosqlite (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.112   Downloading aiosqlite-0.22.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "#8 4.124 Collecting banks<3,>=2.2.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.127   Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "#8 4.142 Collecting dataclasses-json (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.145   Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "#8 4.156 Collecting deprecated>=1.2.9.3 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.159   Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "#8 4.169 Collecting dirtyjson<2,>=1.0.8 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.172   Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "#8 4.181 Collecting filetype<2,>=1.2.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.184   Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "#8 4.200 Collecting fsspec>=2023.5.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.204   Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "#8 4.238 Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.243   Downloading llama_index_workflows-2.12.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "#8 4.254 Collecting nest-asyncio<2,>=1.5.8 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.257   Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "#8 4.273 Collecting networkx>=3.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.277   Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "#8 4.292 Collecting nltk>3.8.1 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.295   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "#8 4.442 Collecting pillow>=9.0.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.446   Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (8.8 kB)\n",
      "#8 4.461 Collecting platformdirs (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.464   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "#8 4.500 Collecting requests>=2.31.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.503   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "#8 4.591 Collecting setuptools>=80.9.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.595   Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "#8 4.775 Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.780   Downloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (9.5 kB)\n",
      "#8 4.816 Collecting tiktoken>=0.7.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.822   Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (6.7 kB)\n",
      "#8 4.846 Collecting tqdm<5,>=4.66.1 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.849   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "#8 4.866 Collecting typing-inspect>=0.8.0 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.869   Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "#8 4.991 Collecting wrapt (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 4.995   Downloading wrapt-2.0.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (9.0 kB)\n",
      "#8 5.010 Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 5.013   Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "#8 5.021 Collecting defusedxml>=0.7.1 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 5.024   Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "#8 5.115 Collecting pandas<3,>=2.0.0 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 5.120   Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl.metadata (91 kB)\n",
      "#8 5.167 Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 5.171   Downloading pypdf-6.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "#8 5.181 Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 5.184   Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "#8 5.200 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 5.204   Downloading aioboto3-15.5.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 5.483 Collecting llama-index-llms-anthropic<0.9,>=0.8.0 (from llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 5.494   Downloading llama_index_llms_anthropic-0.8.6-py3-none-any.whl.metadata (6.2 kB)\n",
      "#8 5.502 Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->-r requirements.txt (line 23))\n",
      "#8 5.506   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "#8 5.991 Collecting pydantic-core==2.41.5 (from pydantic>=2.0.0->-r requirements.txt (line 23))\n",
      "#8 5.996   Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.3 kB)\n",
      "#8 6.006 Collecting typing-inspection>=0.4.2 (from pydantic>=2.0.0->-r requirements.txt (line 23))\n",
      "#8 6.009   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "#8 6.024 Collecting anyio (from httpx>=0.24.0->-r requirements.txt (line 24))\n",
      "#8 6.028   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "#8 6.042 Collecting httpcore==1.* (from httpx>=0.24.0->-r requirements.txt (line 24))\n",
      "#8 6.047   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "#8 6.058 Collecting idna (from httpx>=0.24.0->-r requirements.txt (line 24))\n",
      "#8 6.061   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "#8 6.070 Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.24.0->-r requirements.txt (line 24))\n",
      "#8 6.073   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "#8 6.095 Collecting aiobotocore==2.25.1 (from aiobotocore[boto3]==2.25.1->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.098   Downloading aiobotocore-2.25.1-py3-none-any.whl.metadata (25 kB)\n",
      "#8 6.108 Collecting aiofiles>=23.2.1 (from aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.111   Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "#8 6.135 Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.25.1->aiobotocore[boto3]==2.25.1->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.139   Downloading aioitertools-0.13.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "#8 6.245 INFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 6.245 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.250   Downloading aioboto3-15.4.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 6.259 Collecting aiobotocore==2.25.0 (from aiobotocore[boto3]==2.25.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.262   Downloading aiobotocore-2.25.0-py3-none-any.whl.metadata (25 kB)\n",
      "#8 6.369 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.372   Downloading aioboto3-15.3.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 6.381 Collecting aiobotocore==2.24.3 (from aiobotocore[boto3]==2.24.3->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.384   Downloading aiobotocore-2.24.3-py3-none-any.whl.metadata (25 kB)\n",
      "#8 6.560 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.565   Downloading aioboto3-15.2.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 6.573 Collecting aiobotocore==2.24.2 (from aiobotocore[boto3]==2.24.2->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.576   Downloading aiobotocore-2.24.2-py3-none-any.whl.metadata (25 kB)\n",
      "#8 6.686 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.690   Downloading aioboto3-15.1.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 6.699 Collecting aiobotocore==2.24.0 (from aiobotocore[boto3]==2.24.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.702   Downloading aiobotocore-2.24.0-py3-none-any.whl.metadata (25 kB)\n",
      "#8 6.873 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.882   Downloading aioboto3-15.0.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 6.892 Collecting aiobotocore==2.23.0 (from aiobotocore[boto3]==2.23.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 6.895   Downloading aiobotocore-2.23.0-py3-none-any.whl.metadata (24 kB)\n",
      "#8 7.065 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.069   Downloading aioboto3-14.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.078 Collecting aiobotocore==2.22.0 (from aiobotocore[boto3]==2.22.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.081   Downloading aiobotocore-2.22.0-py3-none-any.whl.metadata (24 kB)\n",
      "#8 7.211 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.215   Downloading aioboto3-14.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.220 INFO: pip is still looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 7.225   Downloading aioboto3-14.1.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.234 Collecting aiobotocore==2.21.1 (from aiobotocore[boto3]==2.21.1->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.237   Downloading aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
      "#8 7.372 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.376   Downloading aioboto3-14.0.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.385 Collecting aiobotocore==2.20.0 (from aiobotocore[boto3]==2.20.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.388   Downloading aiobotocore-2.20.0-py3-none-any.whl.metadata (23 kB)\n",
      "#8 7.516 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.520   Downloading aioboto3-13.4.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 7.529 Collecting aiobotocore==2.18.0 (from aiobotocore[boto3]==2.18.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.533   Downloading aiobotocore-2.18.0-py3-none-any.whl.metadata (23 kB)\n",
      "#8 7.667 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.672   Downloading aioboto3-13.3.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "#8 7.681 Collecting aiobotocore==2.16.0 (from aiobotocore[boto3]==2.16.0->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.685   Downloading aiobotocore-2.16.0-py3-none-any.whl.metadata (23 kB)\n",
      "#8 7.822 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.828   Downloading aioboto3-13.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.837 Collecting aiobotocore==2.15.2 (from aiobotocore[boto3]==2.15.2->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.840   Downloading aiobotocore-2.15.2-py3-none-any.whl.metadata (23 kB)\n",
      "#8 7.972 INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "#8 7.974 Collecting aioboto3<16,>=13.1.1 (from llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.979   Downloading aioboto3-13.1.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "#8 7.988 Collecting aiobotocore==2.13.1 (from aiobotocore[boto3]==2.13.1->aioboto3<16,>=13.1.1->llama-index-embeddings-bedrock>=0.1.0->-r requirements.txt (line 18))\n",
      "#8 7.991   Downloading aiobotocore-2.13.1-py3-none-any.whl.metadata (22 kB)\n",
      "#8 8.148 Collecting llama-index-llms-bedrock>=0.1.0 (from -r requirements.txt (line 19))\n",
      "#8 8.153   Downloading llama_index_llms_bedrock-0.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 8.184 Collecting llama-index-core>=0.10.0 (from -r requirements.txt (line 16))\n",
      "#8 8.188   Downloading llama_index_core-0.13.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "#8 8.194 Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 8.197   Downloading llama_index_workflows-1.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "#8 8.247 Collecting llama-index-llms-bedrock>=0.1.0 (from -r requirements.txt (line 19))\n",
      "#8 8.252   Downloading llama_index_llms_bedrock-0.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 8.307   Downloading llama_index_llms_bedrock-0.3.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.329 INFO: pip is looking at multiple versions of llama-index-llms-bedrock to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 8.334   Downloading llama_index_llms_bedrock-0.3.7-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.342   Downloading llama_index_llms_bedrock-0.3.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.347   Downloading llama_index_llms_bedrock-0.3.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.353   Downloading llama_index_llms_bedrock-0.3.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.360   Downloading llama_index_llms_bedrock-0.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.367   Downloading llama_index_llms_bedrock-0.3.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.373   Downloading llama_index_llms_bedrock-0.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.375 INFO: pip is still looking at multiple versions of llama-index-llms-bedrock to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 8.379   Downloading llama_index_llms_bedrock-0.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.384   Downloading llama_index_llms_bedrock-0.2.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.407   Downloading llama_index_llms_bedrock-0.2.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.416   Downloading llama_index_llms_bedrock-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.423   Downloading llama_index_llms_bedrock-0.2.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.425 INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "#8 8.428   Downloading llama_index_llms_bedrock-0.2.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "#8 8.434   Downloading llama_index_llms_bedrock-0.2.1-py3-none-any.whl.metadata (738 bytes)\n",
      "#8 8.440   Downloading llama_index_llms_bedrock-0.2.0-py3-none-any.whl.metadata (738 bytes)\n",
      "#8 8.445   Downloading llama_index_llms_bedrock-0.1.13-py3-none-any.whl.metadata (739 bytes)\n",
      "#8 8.477   Downloading llama_index_llms_bedrock-0.1.12-py3-none-any.whl.metadata (739 bytes)\n",
      "#8 8.482   Downloading llama_index_llms_bedrock-0.1.11-py3-none-any.whl.metadata (739 bytes)\n",
      "#8 8.487   Downloading llama_index_llms_bedrock-0.1.10-py3-none-any.whl.metadata (739 bytes)\n",
      "#8 8.494   Downloading llama_index_llms_bedrock-0.1.9-py3-none-any.whl.metadata (738 bytes)\n",
      "#8 8.499   Downloading llama_index_llms_bedrock-0.1.8-py3-none-any.whl.metadata (687 bytes)\n",
      "#8 8.505   Downloading llama_index_llms_bedrock-0.1.7-py3-none-any.whl.metadata (687 bytes)\n",
      "#8 8.510   Downloading llama_index_llms_bedrock-0.1.6-py3-none-any.whl.metadata (687 bytes)\n",
      "#8 8.516   Downloading llama_index_llms_bedrock-0.1.5-py3-none-any.whl.metadata (687 bytes)\n",
      "#8 8.521   Downloading llama_index_llms_bedrock-0.1.4-py3-none-any.whl.metadata (687 bytes)\n",
      "#8 8.526   Downloading llama_index_llms_bedrock-0.1.3-py3-none-any.whl.metadata (738 bytes)\n",
      "#8 8.528 Collecting llama-index-embeddings-bedrock>=0.1.0 (from -r requirements.txt (line 18))\n",
      "#8 8.532   Downloading llama_index_embeddings_bedrock-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "#8 8.765   Downloading llama_index_embeddings_bedrock-0.7.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "#8 8.997   Downloading llama_index_embeddings_bedrock-0.7.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "#8 9.234   Downloading llama_index_embeddings_bedrock-0.6.2-py3-none-any.whl.metadata (443 bytes)\n",
      "#8 9.471   Downloading llama_index_embeddings_bedrock-0.6.1-py3-none-any.whl.metadata (443 bytes)\n",
      "#8 9.785   Downloading llama_index_embeddings_bedrock-0.6.0-py3-none-any.whl.metadata (443 bytes)\n",
      "#8 10.03   Downloading llama_index_embeddings_bedrock-0.5.2-py3-none-any.whl.metadata (443 bytes)\n",
      "#8 10.04 INFO: pip is looking at multiple versions of llama-index-embeddings-bedrock to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 10.04   Downloading llama_index_embeddings_bedrock-0.5.1-py3-none-any.whl.metadata (443 bytes)\n",
      "#8 10.05   Downloading llama_index_embeddings_bedrock-0.5.0-py3-none-any.whl.metadata (738 bytes)\n",
      "#8 10.07   Downloading llama_index_embeddings_bedrock-0.4.0-py3-none-any.whl.metadata (695 bytes)\n",
      "#8 10.07   Downloading llama_index_embeddings_bedrock-0.3.1-py3-none-any.whl.metadata (697 bytes)\n",
      "#8 10.08   Downloading llama_index_embeddings_bedrock-0.3.0-py3-none-any.whl.metadata (697 bytes)\n",
      "#8 10.08   Downloading llama_index_embeddings_bedrock-0.2.1-py3-none-any.whl.metadata (646 bytes)\n",
      "#8 10.09   Downloading llama_index_embeddings_bedrock-0.2.0-py3-none-any.whl.metadata (646 bytes)\n",
      "#8 10.09 INFO: pip is still looking at multiple versions of llama-index-embeddings-bedrock to determine which version is compatible with other requirements. This could take a while.\n",
      "#8 10.10   Downloading llama_index_embeddings_bedrock-0.1.5-py3-none-any.whl.metadata (646 bytes)\n",
      "#8 10.10   Downloading llama_index_embeddings_bedrock-0.1.4-py3-none-any.whl.metadata (646 bytes)\n",
      "#8 10.11   Downloading llama_index_embeddings_bedrock-0.1.3-py3-none-any.whl.metadata (697 bytes)\n",
      "#8 10.11 Collecting llama-index-readers-file>=0.1.0 (from -r requirements.txt (line 17))\n",
      "#8 10.12   Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 10.13 Collecting pandas<2.3.0 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 10.13   Downloading pandas-2.2.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (89 kB)\n",
      "#8 11.73 INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "#8 11.73 Collecting llama-index-readers-file>=0.1.0 (from -r requirements.txt (line 17))\n",
      "#8 11.73   Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 13.33   Downloading llama_index_readers_file-0.5.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 14.96   Downloading llama_index_readers_file-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 16.52   Downloading llama_index_readers_file-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "#8 16.53 Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 16.53   Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "#8 18.08 Collecting llama-index-readers-file>=0.1.0 (from -r requirements.txt (line 17))\n",
      "#8 18.08   Downloading llama_index_readers_file-0.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "#8 19.64   Downloading llama_index_readers_file-0.4.11-py3-none-any.whl.metadata (5.3 kB)\n",
      "#8 19.67 Collecting llama-index-core>=0.10.0 (from -r requirements.txt (line 16))\n",
      "#8 19.67   Downloading llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "#8 19.69 Collecting llama-index-llms-anthropic<0.7.0,>=0.6.3 (from llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 19.70   Downloading llama_index_llms_anthropic-0.6.19-py3-none-any.whl.metadata (6.2 kB)\n",
      "#8 20.07 Collecting llama-index-llms-anthropic<0.6.0,>=0.5.0 (from llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 20.07   Downloading llama_index_llms_anthropic-0.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "#8 20.93 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 20.93   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "#8 20.94 Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 20.94   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "#8 20.95 Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 20.96   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "#8 21.00 Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.00   Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (20 kB)\n",
      "#8 21.16 Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.16   Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (5.3 kB)\n",
      "#8 21.20 Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.20   Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "#8 21.37 Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.37   Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (75 kB)\n",
      "#8 21.42 Collecting griffe (from banks<3,>=2.2.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.42   Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "#8 21.44 Collecting jinja2 (from banks<3,>=2.2.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 21.44   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "#8 21.46 Collecting soupsieve>=1.6.1 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 21.46   Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "#8 21.55 Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 21.55   Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "#8 21.60 Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 21.61   Downloading ormsgpack-1.12.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.2 kB)\n",
      "#8 21.86 Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph>=0.1.0->-r requirements.txt (line 13))\n",
      "#8 21.86   Downloading orjson-3.11.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (41 kB)\n",
      "#8 21.89 Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 21.89   Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "#8 21.95 Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1.0->-r requirements.txt (line 11))\n",
      "#8 21.96   Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (3.3 kB)\n",
      "#8 21.98 Collecting chevron==0.14.0 (from launchdarkly-server-sdk-ai>=0.12.0->launchdarkly-server-sdk-ai-langchain>=0.1.0->-r requirements.txt (line 7))\n",
      "#8 21.99   Downloading chevron-0.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "#8 22.03 Collecting anthropic>=0.52.0 (from anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 22.03   Downloading anthropic-0.76.0-py3-none-any.whl.metadata (28 kB)\n",
      "#8 22.07 Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.07   Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "#8 22.12 Collecting click (from nltk>3.8.1->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.13   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "#8 22.14 Collecting joblib (from nltk>3.8.1->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.14   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "#8 22.37 Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.38   Downloading regex-2025.11.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (40 kB)\n",
      "#8 22.44 Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 22.45   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "#8 22.46 Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file>=0.1.0->-r requirements.txt (line 17))\n",
      "#8 22.46   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "#8 22.50 Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore>=1.34.0->-r requirements.txt (line 3))\n",
      "#8 22.50   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "#8 22.58 Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.58   Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (37 kB)\n",
      "#8 22.91 Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.91   Downloading greenlet-3.3.0-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl.metadata (4.1 kB)\n",
      "#8 22.98 Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 22.98   Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "#8 23.08 Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 23.08   Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "#8 23.12 Collecting distro<2,>=1.7.0 (from anthropic>=0.52.0->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.13   Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "#8 23.14 Collecting docstring-parser<1,>=0.15 (from anthropic>=0.52.0->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.14   Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "#8 23.19 Collecting jiter<1,>=0.4.0 (from anthropic>=0.52.0->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.20   Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\n",
      "#8 23.21 Collecting sniffio (from anthropic>=0.52.0->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.22   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "#8 23.51 Collecting google-auth<3,>=2 (from google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.51   Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "#8 23.67 Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 23.67   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#8 23.72 Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.10.0->-r requirements.txt (line 16))\n",
      "#8 23.72   Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.7 kB)\n",
      "#8 23.75 Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.76   Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "#8 23.77 Collecting rsa<5,>=3.1.4 (from google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.77   Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "#8 23.81 Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=2->google-auth[requests]<3,>=2; extra == \"vertex\"->anthropic[bedrock,vertex]>=0.52.0->llama-index-llms-anthropic<0.7.0,>=0.6.3->llama-index-llms-bedrock>=0.1.0->-r requirements.txt (line 19))\n",
      "#8 23.82   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "#8 23.84 Downloading boto3-1.42.27-py3-none-any.whl (140 kB)\n",
      "#8 23.84 Downloading botocore-1.42.27-py3-none-any.whl (14.6 MB)\n",
      "#8 23.87    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 564.1 MB/s eta 0:00:00\n",
      "#8 23.87 Downloading launchdarkly_server_sdk-9.14.1-py3-none-any.whl (290 kB)\n",
      "#8 23.89 Downloading launchdarkly_server_sdk_ai_langchain-0.3.0-py3-none-any.whl (6.0 kB)\n",
      "#8 23.89 Downloading langchain-1.2.3-py3-none-any.whl (106 kB)\n",
      "#8 23.89 Downloading langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
      "#8 23.89 Downloading langchain_aws-1.2.0-py3-none-any.whl (153 kB)\n",
      "#8 23.90 Downloading langgraph-1.0.6-py3-none-any.whl (157 kB)\n",
      "#8 23.90 Downloading llama_index_readers_file-0.4.11-py3-none-any.whl (41 kB)\n",
      "#8 23.91 Downloading llama_index_core-0.12.52.post1-py3-none-any.whl (7.6 MB)\n",
      "#8 23.94    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 235.7 MB/s eta 0:00:00\n",
      "#8 23.95 Downloading llama_index_embeddings_bedrock-0.4.0-py3-none-any.whl (5.5 kB)\n",
      "#8 23.95 Downloading llama_index_llms_bedrock-0.3.8-py3-none-any.whl (11 kB)\n",
      "#8 23.96 Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "#8 23.96 Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n",
      "#8 23.97    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 282.6 MB/s eta 0:00:00\n",
      "#8 23.97 Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "#8 23.98 Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "#8 23.98 Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "#8 23.98 Downloading aiohttp-3.13.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (1.7 MB)\n",
      "#8 23.99    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 227.0 MB/s eta 0:00:00\n",
      "#8 24.00 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "#8 24.00 Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "#8 24.00 Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "#8 24.01 Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "#8 24.01 Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "#8 24.01 Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "#8 24.02 Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "#8 24.02 Downloading expiringdict-1.2.2-py3-none-any.whl (8.5 kB)\n",
      "#8 24.02 Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "#8 24.03 Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "#8 24.03 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "#8 24.04 Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "#8 24.04 Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "#8 24.04 Downloading langgraph_prebuilt-1.0.6-py3-none-any.whl (35 kB)\n",
      "#8 24.05 Downloading langgraph_sdk-0.3.3-py3-none-any.whl (67 kB)\n",
      "#8 24.05 Downloading langsmith-0.6.2-py3-none-any.whl (282 kB)\n",
      "#8 24.06 Downloading launchdarkly_eventsource-1.5.0-py3-none-any.whl (33 kB)\n",
      "#8 24.06 Downloading launchdarkly_server_sdk_ai-0.12.0-py3-none-any.whl (22 kB)\n",
      "#8 24.06 Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
      "#8 24.07 Downloading llama_index_llms_anthropic-0.6.19-py3-none-any.whl (12 kB)\n",
      "#8 24.07 Downloading llama_index_workflows-1.3.0-py3-none-any.whl (42 kB)\n",
      "#8 24.08 Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "#8 24.08 Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "#8 24.08    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 722.4 MB/s eta 0:00:00\n",
      "#8 24.09 Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "#8 24.09    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 849.1 MB/s eta 0:00:00\n",
      "#8 24.09 Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (14.4 MB)\n",
      "#8 24.18    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.4/14.4 MB 181.7 MB/s eta 0:00:00\n",
      "#8 24.18 Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "#8 24.19 Downloading pandas-2.2.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (15.2 MB)\n",
      "#8 24.26    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.2/15.2 MB 225.6 MB/s eta 0:00:00\n",
      "#8 24.26 Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.3 MB)\n",
      "#8 24.28    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 397.4 MB/s eta 0:00:00\n",
      "#8 24.28 Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "#8 24.29 Downloading pyrfc3339-2.1.0-py3-none-any.whl (6.8 kB)\n",
      "#8 24.29 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#8 24.31 Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (775 kB)\n",
      "#8 24.31    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 775.1/775.1 kB 799.6 MB/s eta 0:00:00\n",
      "#8 24.31 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "#8 24.32 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "#8 24.32 Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "#8 24.32 Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "#8 24.32 Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "#8 24.33    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 859.5 MB/s eta 0:00:00\n",
      "#8 24.33 Downloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (3.3 MB)\n",
      "#8 24.35    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 207.8 MB/s eta 0:00:00\n",
      "#8 24.36 Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "#8 24.36 Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "#8 24.37 Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_aarch64.whl (1.1 MB)\n",
      "#8 24.37    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 758.8 MB/s eta 0:00:00\n",
      "#8 24.37 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "#8 24.38 Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "#8 24.38 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "#8 24.38 Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "#8 24.39 Downloading uuid_utils-0.13.0-cp39-abi3-manylinux_2_24_aarch64.whl (340 kB)\n",
      "#8 24.39 Downloading wrapt-2.0.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (123 kB)\n",
      "#8 24.40 Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (212 kB)\n",
      "#8 24.40 Downloading aiosqlite-0.22.1-py3-none-any.whl (17 kB)\n",
      "#8 24.41 Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "#8 24.41 Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "#8 24.41 Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "#8 24.42 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "#8 24.42 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "#8 24.42 Downloading anthropic-0.76.0-py3-none-any.whl (390 kB)\n",
      "#8 24.43 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "#8 24.43 Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (148 kB)\n",
      "#8 24.44 Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (243 kB)\n",
      "#8 24.44 Downloading greenlet-3.3.0-cp312-cp312-manylinux_2_24_aarch64.manylinux_2_28_aarch64.whl (597 kB)\n",
      "#8 24.44    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 597.3/597.3 kB 831.8 MB/s eta 0:00:00\n",
      "#8 24.45 Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "#8 24.45 Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "#8 24.45 Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "#8 24.46 Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "#8 24.46 Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (258 kB)\n",
      "#8 24.46 Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "#8 24.47 Downloading orjson-3.11.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (132 kB)\n",
      "#8 24.47 Downloading ormsgpack-1.12.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (202 kB)\n",
      "#8 24.48 Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (225 kB)\n",
      "#8 24.48 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "#8 24.49 Downloading regex-2025.11.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (798 kB)\n",
      "#8 24.49    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.6/798.6 kB 803.0 MB/s eta 0:00:00\n",
      "#8 24.49 Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "#8 24.49 Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "#8 24.50 Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "#8 24.50 Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "#8 24.50 Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (372 kB)\n",
      "#8 24.51 Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (5.1 MB)\n",
      "#8 24.54    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 174.3 MB/s eta 0:00:00\n",
      "#8 24.54 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "#8 24.55 Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "#8 24.55 Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "#8 24.56 Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "#8 24.56 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#8 24.56 Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "#8 24.56 Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "#8 24.57 Downloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
      "#8 24.57 Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (350 kB)\n",
      "#8 24.58 Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (24 kB)\n",
      "#8 24.58 Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "#8 24.58 Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "#8 24.59 Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "#8 24.59 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "#8 24.96 Installing collected packages: striprtf, pytz, filetype, expiringdict, dirtyjson, chevron, zstandard, xxhash, wrapt, uuid-utils, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, setuptools, semver, regex, pyyaml, pyRFC3339, pypdf, pyasn1, propcache, platformdirs, pillow, packaging, ormsgpack, orjson, numpy, networkx, nest-asyncio, mypy-extensions, multidict, MarkupSafe, jsonpointer, joblib, jmespath, jiter, idna, h11, greenlet, fsspec, frozenlist, docstring-parser, distro, defusedxml, colorama, click, charset_normalizer, certifi, attrs, annotated-types, aiosqlite, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, sqlalchemy, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, nltk, marshmallow, launchdarkly-eventsource, jsonpatch, jinja2, httpcore, griffe, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic, pandas, launchdarkly-server-sdk, httpx, google-auth, dataclasses-json, botocore, aiohttp, s3transfer, llama-index-instrumentation, launchdarkly-server-sdk-ai, langsmith, langgraph-sdk, banks, anthropic, llama-index-workflows, langchain-core, boto3, llama-index-core, langgraph-checkpoint, langchain-aws, llama-index-readers-file, llama-index-llms-anthropic, llama-index-embeddings-bedrock, langgraph-prebuilt, llama-index-llms-bedrock, langgraph, langchain, launchdarkly-server-sdk-ai-langchain\n",
      "#8 41.66 Successfully installed MarkupSafe-3.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 aiosqlite-0.22.1 annotated-types-0.7.0 anthropic-0.76.0 anyio-4.12.1 attrs-25.4.0 banks-2.2.0 beautifulsoup4-4.14.3 boto3-1.42.27 botocore-1.42.27 certifi-2026.1.4 charset_normalizer-3.4.4 chevron-0.14.0 click-8.3.1 colorama-0.4.6 dataclasses-json-0.6.7 defusedxml-0.7.1 deprecated-1.3.1 dirtyjson-1.0.8 distro-1.9.0 docstring-parser-0.17.0 expiringdict-1.2.2 filetype-1.2.0 frozenlist-1.8.0 fsspec-2026.1.0 google-auth-2.47.0 greenlet-3.3.0 griffe-1.15.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jinja2-3.1.6 jiter-0.12.0 jmespath-1.0.1 joblib-1.5.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.2.3 langchain-aws-1.2.0 langchain-core-1.2.7 langgraph-1.0.6 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.6 langgraph-sdk-0.3.3 langsmith-0.6.2 launchdarkly-eventsource-1.5.0 launchdarkly-server-sdk-9.14.1 launchdarkly-server-sdk-ai-0.12.0 launchdarkly-server-sdk-ai-langchain-0.3.0 llama-index-core-0.12.52.post1 llama-index-embeddings-bedrock-0.4.0 llama-index-instrumentation-0.4.2 llama-index-llms-anthropic-0.6.19 llama-index-llms-bedrock-0.3.8 llama-index-readers-file-0.4.11 llama-index-workflows-1.3.0 marshmallow-3.26.2 multidict-6.7.0 mypy-extensions-1.1.0 nest-asyncio-1.6.0 networkx-3.6.1 nltk-3.9.2 numpy-2.4.1 orjson-3.11.5 ormsgpack-1.12.1 packaging-25.0 pandas-2.2.3 pillow-12.1.0 platformdirs-4.5.1 propcache-0.4.1 pyRFC3339-2.1.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 pypdf-5.9.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 rsa-4.9.1 s3transfer-0.16.0 semver-3.0.4 setuptools-80.9.0 six-1.17.0 sniffio-1.3.1 soupsieve-2.8.1 sqlalchemy-2.0.45 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.12.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.3 uuid-utils-0.13.0 wrapt-2.0.1 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n",
      "#8 41.66 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#8 41.76\n",
      "#8 41.76 [notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "#8 41.76 [notice] To update, run: pip install --upgrade pip\n",
      "#8 DONE 43.0s\n",
      "\n",
      "#9 [5/9] RUN pip install bedrock-agentcore\n",
      "#9 0.620 Collecting bedrock-agentcore\n",
      "#9 0.659   Downloading bedrock_agentcore-1.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "#9 0.668 Requirement already satisfied: boto3>=1.40.52 in /usr/local/lib/python3.12/site-packages (from bedrock-agentcore) (1.42.27)\n",
      "#9 0.668 Requirement already satisfied: botocore>=1.40.52 in /usr/local/lib/python3.12/site-packages (from bedrock-agentcore) (1.42.27)\n",
      "#9 0.668 Requirement already satisfied: pydantic<2.41.3,>=2.0.0 in /usr/local/lib/python3.12/site-packages (from bedrock-agentcore) (2.12.5)\n",
      "#9 0.697 Collecting starlette>=0.46.2 (from bedrock-agentcore)\n",
      "#9 0.701   Downloading starlette-0.51.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "#9 0.708 Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/lib/python3.12/site-packages (from bedrock-agentcore) (4.15.0)\n",
      "#9 0.709 Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/site-packages (from bedrock-agentcore) (2.6.3)\n",
      "#9 0.733 Collecting uvicorn>=0.34.2 (from bedrock-agentcore)\n",
      "#9 0.737   Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "#9 0.823 Collecting websockets>=12.0 (from bedrock-agentcore)\n",
      "#9 0.828   Downloading websockets-16.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (6.8 kB)\n",
      "#9 0.837 Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/site-packages (from boto3>=1.40.52->bedrock-agentcore) (1.0.1)\n",
      "#9 0.837 Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/site-packages (from boto3>=1.40.52->bedrock-agentcore) (0.16.0)\n",
      "#9 0.839 Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/site-packages (from botocore>=1.40.52->bedrock-agentcore) (2.9.0.post0)\n",
      "#9 0.842 Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore) (0.7.0)\n",
      "#9 0.842 Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore) (2.41.5)\n",
      "#9 0.842 Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/site-packages (from pydantic<2.41.3,>=2.0.0->bedrock-agentcore) (0.4.2)\n",
      "#9 0.844 Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/site-packages (from starlette>=0.46.2->bedrock-agentcore) (4.12.1)\n",
      "#9 0.847 Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/site-packages (from uvicorn>=0.34.2->bedrock-agentcore) (8.3.1)\n",
      "#9 0.847 Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/site-packages (from uvicorn>=0.34.2->bedrock-agentcore) (0.16.0)\n",
      "#9 0.850 Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette>=0.46.2->bedrock-agentcore) (3.11)\n",
      "#9 0.854 Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.40.52->bedrock-agentcore) (1.17.0)\n",
      "#9 0.862 Downloading bedrock_agentcore-1.2.0-py3-none-any.whl (118 kB)\n",
      "#9 0.879 Downloading starlette-0.51.0-py3-none-any.whl (74 kB)\n",
      "#9 0.889 Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "#9 0.898 Downloading websockets-16.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (186 kB)\n",
      "#9 1.014 Installing collected packages: websockets, uvicorn, starlette, bedrock-agentcore\n",
      "#9 1.292 Successfully installed bedrock-agentcore-1.2.0 starlette-0.51.0 uvicorn-0.40.0 websockets-16.0\n",
      "#9 1.293 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#9 1.403\n",
      "#9 1.403 [notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "#9 1.403 [notice] To update, run: pip install --upgrade pip\n",
      "#9 DONE 1.6s\n",
      "\n",
      "#10 [6/9] RUN pip install aws-opentelemetry-distro\n",
      "#10 0.659 Collecting aws-opentelemetry-distro\n",
      "#10 0.699   Downloading aws_opentelemetry_distro-0.14.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "#10 0.731 Collecting opentelemetry-api==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 0.735   Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "#10 0.756 Collecting opentelemetry-distro==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.760   Downloading opentelemetry_distro-0.54b1-py3-none-any.whl.metadata (1.8 kB)\n",
      "#10 0.778 Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 0.783   Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "#10 0.805 Collecting opentelemetry-exporter-otlp-proto-grpc==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 0.808   Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "#10 0.830 Collecting opentelemetry-exporter-otlp-proto-http==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 0.834   Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "#10 0.854 Collecting opentelemetry-instrumentation-aio-pika==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.858   Downloading opentelemetry_instrumentation_aio_pika-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 0.882 Collecting opentelemetry-instrumentation-aiohttp-client==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.887   Downloading opentelemetry_instrumentation_aiohttp_client-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 0.905 Collecting opentelemetry-instrumentation-aiokafka==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.909   Downloading opentelemetry_instrumentation_aiokafka-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 0.934 Collecting opentelemetry-instrumentation-aiopg==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.938   Downloading opentelemetry_instrumentation_aiopg-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 0.961 Collecting opentelemetry-instrumentation-asgi==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 0.965   Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 0.999 Collecting opentelemetry-instrumentation-asyncpg==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.004   Downloading opentelemetry_instrumentation_asyncpg-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.024 Collecting opentelemetry-instrumentation-aws-lambda==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.028   Downloading opentelemetry_instrumentation_aws_lambda-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "#10 1.048 Collecting opentelemetry-instrumentation-boto3sqs==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.052   Downloading opentelemetry_instrumentation_boto3sqs-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.075 Collecting opentelemetry-instrumentation-boto==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.079   Downloading opentelemetry_instrumentation_boto-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.102 Collecting opentelemetry-instrumentation-botocore==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.107   Downloading opentelemetry_instrumentation_botocore-0.54b1-py3-none-any.whl.metadata (3.1 kB)\n",
      "#10 1.128 Collecting opentelemetry-instrumentation-cassandra==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.133   Downloading opentelemetry_instrumentation_cassandra-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.156 Collecting opentelemetry-instrumentation-celery==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.161   Downloading opentelemetry_instrumentation_celery-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.181 Collecting opentelemetry-instrumentation-confluent-kafka==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.186   Downloading opentelemetry_instrumentation_confluent_kafka-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.209 Collecting opentelemetry-instrumentation-dbapi==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.214   Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.236 Collecting opentelemetry-instrumentation-django==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.243   Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "#10 1.268 Collecting opentelemetry-instrumentation-elasticsearch==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.273   Downloading opentelemetry_instrumentation_elasticsearch-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.300 Collecting opentelemetry-instrumentation-falcon==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.310   Downloading opentelemetry_instrumentation_falcon-0.54b1-py3-none-any.whl.metadata (4.3 kB)\n",
      "#10 1.334 Collecting opentelemetry-instrumentation-fastapi==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.338   Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.361 Collecting opentelemetry-instrumentation-flask==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.365   Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.387 Collecting opentelemetry-instrumentation-grpc==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.391   Downloading opentelemetry_instrumentation_grpc-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.411 Collecting opentelemetry-instrumentation-httpx==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.415   Downloading opentelemetry_instrumentation_httpx-0.54b1-py3-none-any.whl.metadata (7.4 kB)\n",
      "#10 1.440 Collecting opentelemetry-instrumentation-jinja2==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.445   Downloading opentelemetry_instrumentation_jinja2-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.466 Collecting opentelemetry-instrumentation-kafka-python==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.472   Downloading opentelemetry_instrumentation_kafka_python-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.493 Collecting opentelemetry-instrumentation-logging==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.498   Downloading opentelemetry_instrumentation_logging-0.54b1-py3-none-any.whl.metadata (1.9 kB)\n",
      "#10 1.521 Collecting opentelemetry-instrumentation-mysql==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.527   Downloading opentelemetry_instrumentation_mysql-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.545 Collecting opentelemetry-instrumentation-mysqlclient==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.549   Downloading opentelemetry_instrumentation_mysqlclient-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.570 Collecting opentelemetry-instrumentation-pika==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.573   Downloading opentelemetry_instrumentation_pika-0.54b1-py3-none-any.whl.metadata (1.9 kB)\n",
      "#10 1.597 Collecting opentelemetry-instrumentation-psycopg2==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.601   Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.624 Collecting opentelemetry-instrumentation-pymemcache==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.628   Downloading opentelemetry_instrumentation_pymemcache-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.655 Collecting opentelemetry-instrumentation-pymongo==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.659   Downloading opentelemetry_instrumentation_pymongo-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.683 Collecting opentelemetry-instrumentation-pymysql==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.689   Downloading opentelemetry_instrumentation_pymysql-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.712 Collecting opentelemetry-instrumentation-pyramid==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.717   Downloading opentelemetry_instrumentation_pyramid-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.740 Collecting opentelemetry-instrumentation-redis==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.745   Downloading opentelemetry_instrumentation_redis-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.765 Collecting opentelemetry-instrumentation-remoulade==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.769   Downloading opentelemetry_instrumentation_remoulade-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.792 Collecting opentelemetry-instrumentation-requests==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.795   Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl.metadata (2.7 kB)\n",
      "#10 1.818 Collecting opentelemetry-instrumentation-sqlalchemy==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.822   Downloading opentelemetry_instrumentation_sqlalchemy-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 1.846 Collecting opentelemetry-instrumentation-sqlite3==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.850   Downloading opentelemetry_instrumentation_sqlite3-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.875 Collecting opentelemetry-instrumentation-starlette==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.879   Downloading opentelemetry_instrumentation_starlette-0.54b1-py3-none-any.whl.metadata (2.3 kB)\n",
      "#10 1.902 Collecting opentelemetry-instrumentation-system-metrics==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.910   Downloading opentelemetry_instrumentation_system_metrics-0.54b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "#10 1.936 Collecting opentelemetry-instrumentation-tornado==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.940   Downloading opentelemetry_instrumentation_tornado-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.960 Collecting opentelemetry-instrumentation-tortoiseorm==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.965   Downloading opentelemetry_instrumentation_tortoiseorm-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "#10 1.986 Collecting opentelemetry-instrumentation-urllib3==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 1.993   Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl.metadata (4.2 kB)\n",
      "#10 2.016 Collecting opentelemetry-instrumentation-urllib==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 2.021   Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl.metadata (3.5 kB)\n",
      "#10 2.044 Collecting opentelemetry-instrumentation-wsgi==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 2.049   Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "#10 2.072 Collecting opentelemetry-instrumentation==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 2.076   Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "#10 2.094 Collecting opentelemetry-processor-baggage==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 2.098   Downloading opentelemetry_processor_baggage-0.54b1-py3-none-any.whl.metadata (3.3 kB)\n",
      "#10 2.119 Collecting opentelemetry-propagator-aws-xray==1.0.1 (from aws-opentelemetry-distro)\n",
      "#10 2.122   Downloading opentelemetry_propagator_aws_xray-1.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "#10 2.145 Collecting opentelemetry-propagator-b3==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 2.150   Downloading opentelemetry_propagator_b3-1.33.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "#10 2.175 Collecting opentelemetry-propagator-jaeger==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 2.179   Downloading opentelemetry_propagator_jaeger-1.33.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "#10 2.203 Collecting opentelemetry-propagator-ot-trace==0.54b1 (from aws-opentelemetry-distro)\n",
      "#10 2.207   Downloading opentelemetry_propagator_ot_trace-0.54b1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#10 2.224 Collecting opentelemetry-sdk-extension-aws==2.0.2 (from aws-opentelemetry-distro)\n",
      "#10 2.229   Downloading opentelemetry_sdk_extension_aws-2.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "#10 2.252 Collecting opentelemetry-sdk==1.33.1 (from aws-opentelemetry-distro)\n",
      "#10 2.255   Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "#10 2.263 Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.12/site-packages (from opentelemetry-api==1.33.1->aws-opentelemetry-distro) (1.3.1)\n",
      "#10 2.290 Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.33.1->aws-opentelemetry-distro)\n",
      "#10 2.293   Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "#10 2.333 Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-common==1.33.1->aws-opentelemetry-distro)\n",
      "#10 2.336   Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "#10 2.362 Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.33.1->aws-opentelemetry-distro)\n",
      "#10 2.366   Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "#10 2.707 Collecting grpcio<2.0.0,>=1.63.2 (from opentelemetry-exporter-otlp-proto-grpc==1.33.1->aws-opentelemetry-distro)\n",
      "#10 2.712   Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (3.7 kB)\n",
      "#10 2.735 Requirement already satisfied: requests~=2.7 in /usr/local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http==1.33.1->aws-opentelemetry-distro) (2.32.5)\n",
      "#10 2.764 Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation==0.54b1->aws-opentelemetry-distro)\n",
      "#10 2.768   Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "#10 2.774 Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.54b1->aws-opentelemetry-distro) (25.0)\n",
      "#10 2.866 Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.54b1->aws-opentelemetry-distro)\n",
      "#10 2.870   Downloading wrapt-1.17.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (6.4 kB)\n",
      "#10 2.907 Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-aiohttp-client==0.54b1->aws-opentelemetry-distro)\n",
      "#10 2.912   Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "#10 2.956 Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->aws-opentelemetry-distro)\n",
      "#10 2.960   Downloading asgiref-3.11.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "#10 3.104 Collecting psutil<8,>=5.9.0 (from opentelemetry-instrumentation-system-metrics==0.54b1->aws-opentelemetry-distro)\n",
      "#10 3.108   Downloading psutil-7.2.1-cp36-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (22 kB)\n",
      "#10 3.163 Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/site-packages (from opentelemetry-sdk==1.33.1->aws-opentelemetry-distro) (4.15.0)\n",
      "#10 3.301 Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.33.1->opentelemetry-exporter-otlp-proto-common==1.33.1->aws-opentelemetry-distro)\n",
      "#10 3.306   Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_aarch64.whl.metadata (592 bytes)\n",
      "#10 3.395 Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.33.1->aws-opentelemetry-distro)\n",
      "#10 3.398   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "#10 3.412 Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.33.1->aws-opentelemetry-distro) (3.4.4)\n",
      "#10 3.412 Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.33.1->aws-opentelemetry-distro) (3.11)\n",
      "#10 3.412 Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.33.1->aws-opentelemetry-distro) (2.6.3)\n",
      "#10 3.413 Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.33.1->aws-opentelemetry-distro) (2026.1.4)\n",
      "#10 3.437 Downloading aws_opentelemetry_distro-0.14.1-py3-none-any.whl (169 kB)\n",
      "#10 3.448 Downloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "#10 3.459 Downloading opentelemetry_distro-0.54b1-py3-none-any.whl (3.3 kB)\n",
      "#10 3.468 Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "#10 3.476 Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "#10 3.486 Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n",
      "#10 3.494 Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "#10 3.504 Downloading opentelemetry_instrumentation_aio_pika-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.513 Downloading opentelemetry_instrumentation_aiohttp_client-0.54b1-py3-none-any.whl (11 kB)\n",
      "#10 3.522 Downloading opentelemetry_instrumentation_aiokafka-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.531 Downloading opentelemetry_instrumentation_aiopg-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.541 Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "#10 3.550 Downloading opentelemetry_instrumentation_asyncpg-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.559 Downloading opentelemetry_instrumentation_aws_lambda-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.567 Downloading opentelemetry_instrumentation_boto-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.576 Downloading opentelemetry_instrumentation_boto3sqs-0.54b1-py3-none-any.whl (11 kB)\n",
      "#10 3.585 Downloading opentelemetry_instrumentation_botocore-0.54b1-py3-none-any.whl (35 kB)\n",
      "#10 3.595 Downloading opentelemetry_instrumentation_cassandra-0.54b1-py3-none-any.whl (8.9 kB)\n",
      "#10 3.604 Downloading opentelemetry_instrumentation_celery-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.614 Downloading opentelemetry_instrumentation_confluent_kafka-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.623 Downloading opentelemetry_instrumentation_dbapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.632 Downloading opentelemetry_instrumentation_django-0.54b1-py3-none-any.whl (19 kB)\n",
      "#10 3.641 Downloading opentelemetry_instrumentation_elasticsearch-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.650 Downloading opentelemetry_instrumentation_falcon-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.660 Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.670 Downloading opentelemetry_instrumentation_flask-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.680 Downloading opentelemetry_instrumentation_grpc-0.54b1-py3-none-any.whl (27 kB)\n",
      "#10 3.689 Downloading opentelemetry_instrumentation_httpx-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.698 Downloading opentelemetry_instrumentation_jinja2-0.54b1-py3-none-any.whl (9.4 kB)\n",
      "#10 3.707 Downloading opentelemetry_instrumentation_kafka_python-0.54b1-py3-none-any.whl (11 kB)\n",
      "#10 3.715 Downloading opentelemetry_instrumentation_logging-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.724 Downloading opentelemetry_instrumentation_mysql-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.734 Downloading opentelemetry_instrumentation_mysqlclient-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.743 Downloading opentelemetry_instrumentation_pika-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.751 Downloading opentelemetry_instrumentation_psycopg2-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.763 Downloading opentelemetry_instrumentation_pymemcache-0.54b1-py3-none-any.whl (9.7 kB)\n",
      "#10 3.773 Downloading opentelemetry_instrumentation_pymongo-0.54b1-py3-none-any.whl (11 kB)\n",
      "#10 3.784 Downloading opentelemetry_instrumentation_pymysql-0.54b1-py3-none-any.whl (10.0 kB)\n",
      "#10 3.793 Downloading opentelemetry_instrumentation_pyramid-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.801 Downloading opentelemetry_instrumentation_redis-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.811 Downloading opentelemetry_instrumentation_remoulade-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.819 Downloading opentelemetry_instrumentation_requests-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.829 Downloading opentelemetry_instrumentation_sqlalchemy-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.838 Downloading opentelemetry_instrumentation_sqlite3-0.54b1-py3-none-any.whl (9.3 kB)\n",
      "#10 3.847 Downloading opentelemetry_instrumentation_starlette-0.54b1-py3-none-any.whl (11 kB)\n",
      "#10 3.856 Downloading opentelemetry_instrumentation_system_metrics-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.865 Downloading opentelemetry_instrumentation_tornado-0.54b1-py3-none-any.whl (15 kB)\n",
      "#10 3.874 Downloading opentelemetry_instrumentation_tortoiseorm-0.54b1-py3-none-any.whl (10 kB)\n",
      "#10 3.884 Downloading opentelemetry_instrumentation_urllib-0.54b1-py3-none-any.whl (12 kB)\n",
      "#10 3.894 Downloading opentelemetry_instrumentation_urllib3-0.54b1-py3-none-any.whl (13 kB)\n",
      "#10 3.902 Downloading opentelemetry_instrumentation_wsgi-0.54b1-py3-none-any.whl (14 kB)\n",
      "#10 3.911 Downloading opentelemetry_processor_baggage-0.54b1-py3-none-any.whl (8.9 kB)\n",
      "#10 3.919 Downloading opentelemetry_propagator_aws_xray-1.0.1-py3-none-any.whl (10 kB)\n",
      "#10 3.928 Downloading opentelemetry_propagator_b3-1.33.1-py3-none-any.whl (8.9 kB)\n",
      "#10 3.938 Downloading opentelemetry_propagator_jaeger-1.33.1-py3-none-any.whl (8.8 kB)\n",
      "#10 3.959 Downloading opentelemetry_propagator_ot_trace-0.54b1-py3-none-any.whl (4.8 kB)\n",
      "#10 3.968 Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "#10 3.978 Downloading opentelemetry_sdk_extension_aws-2.0.2-py3-none-any.whl (18 kB)\n",
      "#10 3.986 Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "#10 3.994 Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "#10 4.004 Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "#10 4.012 Downloading asgiref-3.11.0-py3-none-any.whl (24 kB)\n",
      "#10 4.020 Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "#10 4.039 Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (6.4 MB)\n",
      "#10 4.086    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.4/6.4 MB 136.3 MB/s eta 0:00:00\n",
      "#10 4.090 Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "#10 4.097 Downloading psutil-7.2.1-cp36-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (156 kB)\n",
      "#10 4.104 Downloading wrapt-1.17.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (88 kB)\n",
      "#10 4.111 Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_aarch64.whl (319 kB)\n",
      "#10 4.120 Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "#10 4.341 Installing collected packages: zipp, wrapt, psutil, protobuf, opentelemetry-util-http, grpcio, asgiref, opentelemetry-proto, importlib-metadata, googleapis-common-protos, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-propagator-jaeger, opentelemetry-propagator-b3, opentelemetry-propagator-aws-xray, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-sdk-extension-aws, opentelemetry-propagator-ot-trace, opentelemetry-processor-baggage, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-tortoiseorm, opentelemetry-instrumentation-tornado, opentelemetry-instrumentation-system-metrics, opentelemetry-instrumentation-sqlalchemy, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-remoulade, opentelemetry-instrumentation-redis, opentelemetry-instrumentation-pymongo, opentelemetry-instrumentation-pymemcache, opentelemetry-instrumentation-pika, opentelemetry-instrumentation-logging, opentelemetry-instrumentation-kafka-python, opentelemetry-instrumentation-jinja2, opentelemetry-instrumentation-httpx, opentelemetry-instrumentation-grpc, opentelemetry-instrumentation-elasticsearch, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-confluent-kafka, opentelemetry-instrumentation-celery, opentelemetry-instrumentation-cassandra, opentelemetry-instrumentation-botocore, opentelemetry-instrumentation-boto3sqs, opentelemetry-instrumentation-boto, opentelemetry-instrumentation-aws-lambda, opentelemetry-instrumentation-asyncpg, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-aiokafka, opentelemetry-instrumentation-aiohttp-client, opentelemetry-instrumentation-aio-pika, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-distro, opentelemetry-instrumentation-starlette, opentelemetry-instrumentation-sqlite3, opentelemetry-instrumentation-pyramid, opentelemetry-instrumentation-pymysql, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-mysqlclient, opentelemetry-instrumentation-mysql, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-falcon, opentelemetry-instrumentation-django, opentelemetry-instrumentation-aiopg, aws-opentelemetry-distro\n",
      "#10 4.353   Attempting uninstall: wrapt\n",
      "#10 4.357     Found existing installation: wrapt 2.0.1\n",
      "#10 4.359     Uninstalling wrapt-2.0.1:\n",
      "#10 4.363       Successfully uninstalled wrapt-2.0.1\n",
      "#10 5.627 Successfully installed asgiref-3.11.0 aws-opentelemetry-distro-0.14.1 googleapis-common-protos-1.72.0 grpcio-1.76.0 importlib-metadata-8.6.1 opentelemetry-api-1.33.1 opentelemetry-distro-0.54b1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-aio-pika-0.54b1 opentelemetry-instrumentation-aiohttp-client-0.54b1 opentelemetry-instrumentation-aiokafka-0.54b1 opentelemetry-instrumentation-aiopg-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-asyncpg-0.54b1 opentelemetry-instrumentation-aws-lambda-0.54b1 opentelemetry-instrumentation-boto-0.54b1 opentelemetry-instrumentation-boto3sqs-0.54b1 opentelemetry-instrumentation-botocore-0.54b1 opentelemetry-instrumentation-cassandra-0.54b1 opentelemetry-instrumentation-celery-0.54b1 opentelemetry-instrumentation-confluent-kafka-0.54b1 opentelemetry-instrumentation-dbapi-0.54b1 opentelemetry-instrumentation-django-0.54b1 opentelemetry-instrumentation-elasticsearch-0.54b1 opentelemetry-instrumentation-falcon-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-instrumentation-flask-0.54b1 opentelemetry-instrumentation-grpc-0.54b1 opentelemetry-instrumentation-httpx-0.54b1 opentelemetry-instrumentation-jinja2-0.54b1 opentelemetry-instrumentation-kafka-python-0.54b1 opentelemetry-instrumentation-logging-0.54b1 opentelemetry-instrumentation-mysql-0.54b1 opentelemetry-instrumentation-mysqlclient-0.54b1 opentelemetry-instrumentation-pika-0.54b1 opentelemetry-instrumentation-psycopg2-0.54b1 opentelemetry-instrumentation-pymemcache-0.54b1 opentelemetry-instrumentation-pymongo-0.54b1 opentelemetry-instrumentation-pymysql-0.54b1 opentelemetry-instrumentation-pyramid-0.54b1 opentelemetry-instrumentation-redis-0.54b1 opentelemetry-instrumentation-remoulade-0.54b1 opentelemetry-instrumentation-requests-0.54b1 opentelemetry-instrumentation-sqlalchemy-0.54b1 opentelemetry-instrumentation-sqlite3-0.54b1 opentelemetry-instrumentation-starlette-0.54b1 opentelemetry-instrumentation-system-metrics-0.54b1 opentelemetry-instrumentation-tornado-0.54b1 opentelemetry-instrumentation-tortoiseorm-0.54b1 opentelemetry-instrumentation-urllib-0.54b1 opentelemetry-instrumentation-urllib3-0.54b1 opentelemetry-instrumentation-wsgi-0.54b1 opentelemetry-processor-baggage-0.54b1 opentelemetry-propagator-aws-xray-1.0.1 opentelemetry-propagator-b3-1.33.1 opentelemetry-propagator-jaeger-1.33.1 opentelemetry-propagator-ot-trace-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-sdk-extension-aws-2.0.2 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 protobuf-5.29.5 psutil-7.2.1 wrapt-1.17.3 zipp-3.23.0\n",
      "#10 5.627 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#10 5.661\n",
      "#10 5.661 [notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "#10 5.661 [notice] To update, run: pip install --upgrade pip\n",
      "#10 DONE 6.0s\n",
      "\n",
      "#11 [7/9] COPY ./*.py ./\n",
      "#11 DONE 0.1s\n",
      "\n",
      "#12 [8/9] COPY ./storage ./storage\n",
      "#12 DONE 0.1s\n",
      "\n",
      "#13 [9/9] COPY ./data ./data\n",
      "#13 DONE 0.1s\n",
      "\n",
      "#14 exporting to image\n",
      "#14 exporting layers\n",
      "#14 exporting layers 1.9s done\n",
      "#14 writing image sha256:903f4b60ff7a62f2abb84440e70b2544b8899db2a39b45aa0a4ba42c389a0b98 done\n",
      "#14 naming to docker.io/library/langgraph-agent-repo:latest done\n",
      "#14 DONE 1.9s\n",
      "\n",
      " \u001b[33m11 warnings found (use docker --debug to expand):\n",
      "\u001b[0m - UndefinedVar: Usage of undefined variable '$AWS_DEFAULT_REGION' (line 20)\n",
      " - UndefinedVar: Usage of undefined variable '$LAUNCHDARKLY_SDK_KEY' (line 23)\n",
      " - SecretsUsedInArgOrEnv: Do not use ARG or ENV instructions for sensitive data (ENV \"LAUNCHDARKLY_SDK_KEY\") (line 23)\n",
      " - SecretsUsedInArgOrEnv: Do not use ARG or ENV instructions for sensitive data (ENV \"LAUNCHDARKLY_AGENT_KEY\") (line 24)\n",
      " - UndefinedVar: Usage of undefined variable '$LLAMAINDEX_DATA_DIR' (line 28)\n",
      " - UndefinedVar: Usage of undefined variable '$INVENTORY_LAMBDA' (line 31)\n",
      " - UndefinedVar: Usage of undefined variable '$USER_LAMBDA' (line 32)\n",
      " - UndefinedVar: Usage of undefined variable '$ENABLE_FALLBACK_TOOLS' (line 35)\n",
      " - FromPlatformFlagConstDisallowed: FROM --platform flag should not use constant value \"linux/arm64\" (line 2)\n",
      " - UndefinedVar: Usage of undefined variable '$LAUNCHDARKLY_AGENT_KEY' (line 24)\n",
      " - UndefinedVar: Usage of undefined variable '$LLAMAINDEX_STORAGE_DIR' (line 27)\n",
      "\n",
      "[Container] 2026/01/14 04:37:04.033973 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2026/01/14 04:37:04.056582 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2026/01/14 04:37:04.056597 Phase context status code:  Message:\n",
      "[Container] 2026/01/14 04:37:04.095998 Entering phase POST_BUILD\n",
      "[Container] 2026/01/14 04:37:04.097051 Running command echo Build completed on `date`\n",
      "Build completed on Wed Jan 14 04:37:04 UTC 2026\n",
      "\n",
      "[Container] 2026/01/14 04:37:04.106455 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2026/01/14 04:37:04.114797 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [955116512041.dkr.ecr.us-east-1.amazonaws.com/langgraph-agent-repo]\n",
      "f32a89256c91: Preparing\n",
      "901a193b14dd: Preparing\n",
      "bedc25980c01: Preparing\n",
      "a1c36355ae2e: Preparing\n",
      "52fa17303197: Preparing\n",
      "e6c52f0f1bd4: Preparing\n",
      "d6ed24935344: Preparing\n",
      "a2046d89900e: Preparing\n",
      "4321aacaa6f0: Preparing\n",
      "f44c207e7378: Preparing\n",
      "6bac9ace72b0: Preparing\n",
      "27718dd4c00f: Preparing\n",
      "d6ed24935344: Waiting\n",
      "a2046d89900e: Waiting\n",
      "4321aacaa6f0: Waiting\n",
      "f44c207e7378: Waiting\n",
      "6bac9ace72b0: Waiting\n",
      "27718dd4c00f: Waiting\n",
      "e6c52f0f1bd4: Waiting\n",
      "f32a89256c91: Pushed\n",
      "bedc25980c01: Pushed\n",
      "901a193b14dd: Pushed\n",
      "52fa17303197: Pushed\n",
      "4321aacaa6f0: Layer already exists\n",
      "f44c207e7378: Layer already exists\n",
      "6bac9ace72b0: Layer already exists\n",
      "a2046d89900e: Pushed\n",
      "d6ed24935344: Pushed\n",
      "a1c36355ae2e: Pushed\n",
      "27718dd4c00f: Pushed\n",
      "e6c52f0f1bd4: Pushed\n",
      "\n",
      "Build complete, status = SUCCEEDED\n",
      "Image URI: 955116512041.dkr.ecr.us-east-1.amazonaws.com/langgraph-agent-repo:latest\n",
      "✅ Image verified in repository: langgraph-agent-repo\n"
     ]
    }
   ],
   "source": [
    "# Verify AWS credentials and build configuration\n",
    "print(\"Build Configuration:\")\n",
    "print(f\"  AWS Profile: bedrock-demo\")\n",
    "print(f\"  Solution Role: {SolutionAccessRoleArn}\")\n",
    "print(f\"  S3 Bucket: {CodeBucketForAutomationARN}\")\n",
    "\n",
    "# Kick start building arm64 container image\n",
    "role_name = SolutionAccessRoleArn.split('/')[-1]\n",
    "repository_name = \"langgraph-agent-repo\"\n",
    "\n",
    "# Extract bucket name correctly from ARN\n",
    "if ':::' in CodeBucketForAutomationARN:\n",
    "    bucket_name = CodeBucketForAutomationARN.split(':::')[-1]\n",
    "else:\n",
    "    # Handle case where it's just a bucket name or different ARN format\n",
    "    bucket_name = CodeBucketForAutomationARN.replace('arn:aws:s3:::', '')\n",
    "\n",
    "print(f\"  Role Name: {role_name}\")\n",
    "print(f\"  Bucket Name: {bucket_name}\")\n",
    "print(f\"  ECR Repository: {repository_name}\")\n",
    "print()\n",
    "\n",
    "# Build the Docker image with VERBOSE OUTPUT to see errors\n",
    "try:\n",
    "    ecr_uri = build_arm64_image(role_name, bucket_name, repository_name, verbose=True)  # Changed to verbose=True\n",
    "\n",
    "    # Verify the image exists in ECR\n",
    "    try:\n",
    "        ecr_client = boto3.client('ecr', region_name='us-east-1')\n",
    "        response = ecr_client.describe_images(\n",
    "            repositoryName=repository_name,\n",
    "            imageIds=[{'imageTag': 'latest'}]\n",
    "        )\n",
    "        print(f\"✅ Image verified in repository: {repository_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning verifying image: {str(e)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Build failed: {str(e)}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check the build logs above for specific errors\")\n",
    "    print(\"2. Common issues:\")\n",
    "    print(\"   - Missing files in the Docker build\")\n",
    "    print(\"   - S3 bucket permissions\")\n",
    "    print(\"   - IAM role permissions for CodeBuild\")\n",
    "    print(\"   - Docker image build errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy AgentCore Runtime\n",
    "\n",
    "Create the AgentCore Runtime using boto3 APIs with the Docker image we built in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing AgentCore Runtime ID: LangGraphAgentCoreRuntime-q81sPwHgst\n",
      "Environment variables configured:\n",
      "  AWS_DEFAULT_REGION: us-east-1\n",
      "  LAUNCHDARKLY_SDK_KEY: ***hidden***\n",
      "  LAUNCHDARKLY_AGENT_KEY: ***hidden***\n",
      "  LLAMAINDEX_STORAGE_DIR: ./storage\n",
      "  LLAMAINDEX_DATA_DIR: ./data\n",
      "  ENABLE_FALLBACK_TOOLS: false\n",
      "  INVENTORY_LAMBDA: team-PetStoreInventoryManagementFunction\n",
      "  USER_LAMBDA: team-PetStoreUserManagementFunction\n",
      "Updated existing AgentCore Runtime\n"
     ]
    }
   ],
   "source": [
    "# Create or Update AgentCore Runtime with LaunchDarkly configuration\n",
    "existing_runtime = None\n",
    "region = boto3.Session().region_name\n",
    "agent_runtime_name = \"LangGraphAgentCoreRuntime\"\n",
    "agentcore_control_client = boto3.client('bedrock-agentcore-control')\n",
    "\n",
    "# Try to get existing agent runtime first\n",
    "list_response = agentcore_control_client.list_agent_runtimes()\n",
    "for runtime in list_response.get('agentRuntimes', []):\n",
    "    if runtime['agentRuntimeName'] == agent_runtime_name:\n",
    "        existing_runtime = runtime\n",
    "        agent_runtime_id = existing_runtime['agentRuntimeId']\n",
    "        agent_runtime_arn = existing_runtime['agentRuntimeArn']\n",
    "        print(f\"Found existing AgentCore Runtime ID: {agent_runtime_id}\")\n",
    "\n",
    "# Build environment variables from LaunchDarkly config\n",
    "environment_variables = {\n",
    "    \"AWS_DEFAULT_REGION\": aws_region,\n",
    "    \"LAUNCHDARKLY_SDK_KEY\": LAUNCHDARKLY_SDK_KEY,\n",
    "    \"LAUNCHDARKLY_AGENT_KEY\": LAUNCHDARKLY_AGENT_KEY,\n",
    "    \"LLAMAINDEX_STORAGE_DIR\": llamaindex_config.get(\"storage_dir\", \"./storage\"),\n",
    "    \"LLAMAINDEX_DATA_DIR\": llamaindex_config.get(\"data_dir\", \"./data\"),\n",
    "    \"ENABLE_FALLBACK_TOOLS\": \"false\"  # Set to false in production\n",
    "}\n",
    "\n",
    "# Add Lambda function names if available from LaunchDarkly\n",
    "if lambda_functions.get(\"inventory_lambda\"):\n",
    "    environment_variables[\"INVENTORY_LAMBDA\"] = lambda_functions[\"inventory_lambda\"]\n",
    "if lambda_functions.get(\"user_lambda\"):\n",
    "    environment_variables[\"USER_LAMBDA\"] = lambda_functions[\"user_lambda\"]\n",
    "\n",
    "print(f\"Environment variables configured:\")\n",
    "for key, value in environment_variables.items():\n",
    "    if \"KEY\" in key:\n",
    "        print(f\"  {key}: ***hidden***\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "if existing_runtime: # Update the existing runtime\n",
    "    update_response = agentcore_control_client.update_agent_runtime(\n",
    "        agentRuntimeId=agent_runtime_id,\n",
    "        roleArn=SolutionAccessRoleArn,\n",
    "        agentRuntimeArtifact={\n",
    "            \"containerConfiguration\": {\n",
    "                \"containerUri\": ecr_uri\n",
    "            }\n",
    "        },\n",
    "        networkConfiguration={\n",
    "            \"networkMode\": \"PUBLIC\"\n",
    "        },\n",
    "        environmentVariables=environment_variables,\n",
    "        lifecycleConfiguration={\n",
    "            \"maxLifetime\": 60\n",
    "        }\n",
    "    )\n",
    "    print(f\"Updated existing AgentCore Runtime\")\n",
    "else: # Create new runtime\n",
    "    create_response = agentcore_control_client.create_agent_runtime(\n",
    "        agentRuntimeName=agent_runtime_name,\n",
    "        roleArn=SolutionAccessRoleArn,\n",
    "        agentRuntimeArtifact={\n",
    "            \"containerConfiguration\": {\n",
    "                \"containerUri\": ecr_uri\n",
    "            }\n",
    "        },\n",
    "        networkConfiguration={\n",
    "            \"networkMode\": \"PUBLIC\"\n",
    "        },\n",
    "        environmentVariables=environment_variables,\n",
    "        lifecycleConfiguration={\n",
    "            \"maxLifetime\": 60\n",
    "        }\n",
    "    )\n",
    "    agent_runtime_id = create_response['agentRuntimeId']\n",
    "    agent_runtime_arn = create_response['agentRuntimeArn']\n",
    "    print(f\"Created new AgentCore Runtime ID: {agent_runtime_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for AgentCore Runtime to be ready...\n",
      "Runtime status: UPDATING\n",
      "Runtime status: READY\n"
     ]
    }
   ],
   "source": [
    "def check_runtime_status(agent_runtime_id):\n",
    "    \"\"\"Check the status of the AgentCore Runtime\"\"\"\n",
    "    response = agentcore_control_client.get_agent_runtime(\n",
    "        agentRuntimeId=agent_runtime_id\n",
    "    )\n",
    "    return response['status']\n",
    "\n",
    "# Wait for the runtime to be ready\n",
    "print(\"Waiting for AgentCore Runtime to be ready...\")\n",
    "runtime_status = check_runtime_status(agent_runtime_id)\n",
    "while runtime_status not in ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']:\n",
    "    print(f\"Runtime status: {runtime_status}\")\n",
    "    time.sleep(10)\n",
    "    runtime_status = check_runtime_status(agent_runtime_id)\n",
    "print(f\"Runtime status: {runtime_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Agent Runtime Deployment\n",
    "\n",
    "Send a test prompt to the AgentCore Runtime to verify that the agent is live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Agent Configuration:\n",
      "   Model: amazon.nova-pro-v1:0 (Bedrock)\n",
      "   Tools enabled: retrieve_product_info, get_inventory, retrieve_pet_care, get_user_by_email, get_user_by_id\n",
      "   LlamaIndex Storage: ./storage\n",
      "\n",
      "📝 Query: What is the price of Doggy Delights?\n",
      "✅ Response:\n",
      "{\n",
      "  \"status\": \"Accept\",\n",
      "  \"message\": \"Here is the price of Doggy Delights.\",\n",
      "  \"customerType\": \"Guest\",\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"productId\": \"DD006\",\n",
      "      \"price\": 54.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 54.99,\n",
      "      \"replenishInventory\": false\n",
      "    }\n",
      "  ],\n",
      "  \"shippingCost\": 14.95,\n",
      "  \"petAdvice\": \"\",\n",
      "  \"subtotal\": 54.99,\n",
      "  \"additionalDiscount\": 0,\n",
      "  \"total\": 69.94\n",
      "}\n",
      "--------------------------------------------------\n",
      "📝 Query: Tell me about your cat products\n",
      "✅ Response:\n",
      "{\n",
      "  \"status\": \"Accept\",\n",
      "  \"message\": \"Here are our cat products:\",\n",
      "  \"customerType\": \"Guest\",\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"productId\": \"KC015\",\n",
      "      \"price\": 129.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 129.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"CM001\",\n",
      "      \"price\": 24.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 24.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"PT003\",\n",
      "      \"price\": 15.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 15.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"KK005\",\n",
      "      \"price\": 8.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 8.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"SS007\",\n",
      "      \"price\": 79.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 79.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"CC009\",\n",
      "      \"price\": 11.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 11.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"LL011\",\n",
      "      \"price\": 29.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 29.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"PP020\",\n",
      "      \"price\": 24.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 24.99,\n",
      "      \"replenishInventory\": false\n",
      "    },\n",
      "    {\n",
      "      \"productId\": \"WF008\",\n",
      "      \"price\": 42.99,\n",
      "      \"quantity\": 1,\n",
      "      \"bundleDiscount\": 0,\n",
      "      \"total\": 42.99,\n",
      "      \"replenishInventory\": false\n",
      "    }\n",
      "  ],\n",
      "  \"shippingCost\": 14.95,\n",
      "  \"petAdvice\": \"\",\n",
      "  \"subtotal\": 348.82,\n",
      "  \"additionalDiscount\": 0,\n",
      "  \"total\": 363.77\n",
      "}\n",
      "--------------------------------------------------\n",
      "📝 Query: How often should I bathe a Chihuahua?\n",
      "✅ Response:\n",
      "{\n",
      "  \"status\": \"Accept\",\n",
      "  \"message\": \"Here's the pet care advice for bathing a Chihuahua: Every 3-4 weeks or when dirty. Use lukewarm water, dog-specific gentle shampoo, and dry thoroughly to prevent chills. Consider using a low-heat blow dryer on the cool setting. Regular brushing between baths helps maintain coat health.\",\n",
      "  \"customerType\": \"Guest\",\n",
      "  \"items\": [],\n",
      "  \"shippingCost\": 0,\n",
      "  \"petAdvice\": \"Every 3-4 weeks or when dirty. Use lukewarm water, dog-specific gentle shampoo, and dry thoroughly to prevent chills. Consider using a low-heat blow dryer on the cool setting. Regular brushing between baths helps maintain coat health.\",\n",
      "  \"subtotal\": 0,\n",
      "  \"additionalDiscount\": 0,\n",
      "  \"total\": 0\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "✨ Agent is using LlamaIndex for retrieval - no Knowledge Base IDs required!\n",
      "   RAG tools available: retrieve_product_info, retrieve_pet_care\n",
      "   Lambda tools available: get_inventory, get_user_by_email, get_user_by_id\n"
     ]
    }
   ],
   "source": [
    "# Create a client for the AgentCore data plane\n",
    "agentcore_client = boto3.client('bedrock-agentcore')\n",
    "\n",
    "# Show current configuration being used\n",
    "print(\"🔧 Agent Configuration:\")\n",
    "print(f\"   Model: {agent_config['model']['name']} ({agent_config['model']['provider']})\")\n",
    "print(f\"   Tools enabled: {', '.join(tools_enabled)}\")\n",
    "print(f\"   LlamaIndex Storage: {llamaindex_config.get('storage_dir', './storage')}\")\n",
    "print()\n",
    "\n",
    "# Test the AgentCore Runtime with sample queries\n",
    "test_queries = [\n",
    "    \"What is the price of Doggy Delights?\",\n",
    "    \"Tell me about your cat products\",\n",
    "    \"How often should I bathe a Chihuahua?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"📝 Query: {query}\")\n",
    "\n",
    "    try:\n",
    "        invoke_response = agentcore_client.invoke_agent_runtime(\n",
    "            agentRuntimeArn=agent_runtime_arn,\n",
    "            qualifier=\"DEFAULT\",\n",
    "            traceId=str(uuid.uuid4()),\n",
    "            contentType=\"application/json\",\n",
    "            payload=json.dumps({\n",
    "                \"prompt\": query,\n",
    "                \"user_id\": \"test_user\",\n",
    "                \"subscription_status\": \"active\"\n",
    "            })\n",
    "        )\n",
    "\n",
    "        # Process the response\n",
    "        if \"text/event-stream\" in invoke_response.get(\"contentType\", \"\"):\n",
    "            content = []\n",
    "            for line in invoke_response[\"response\"].iter_lines(chunk_size=1):\n",
    "                if line:\n",
    "                    line = line.decode(\"utf-8\")\n",
    "                    if line.startswith(\"data: \"):\n",
    "                        line = line[6:]\n",
    "                        content.append(line)\n",
    "            response_text = \"\\n\".join(content)\n",
    "        else:\n",
    "            events = []\n",
    "            for event in invoke_response.get(\"response\", []):\n",
    "                events.append(event)\n",
    "\n",
    "            # Combine all events to fix truncation\n",
    "            combined_content = \"\"\n",
    "            for event in events:\n",
    "                combined_content += event.decode(\"utf-8\")\n",
    "\n",
    "            response_text = json.loads(combined_content)\n",
    "\n",
    "        print(f\"✅ Response:\")\n",
    "        if isinstance(response_text, dict):\n",
    "            print(json.dumps(response_text, indent=2))\n",
    "        else:\n",
    "            print(response_text)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n✨ Agent is using LlamaIndex for retrieval - no Knowledge Base IDs required!\")\n",
    "print(f\"   RAG tools available: retrieve_product_info, retrieve_pet_care\")\n",
    "print(f\"   Lambda tools available: get_inventory, get_user_by_email, get_user_by_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Cleanup Resources (Optional)\n",
    "\n",
    "Clean up the AWS resources created in this notebook to avoid incurring unnecessary charges by uncommenting the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_resources():\n",
    "    '''Clean up AWS resources created in this notebook.'''  \n",
    "    # Delete the AgentCore Runtime\n",
    "    try:\n",
    "        agentcore_control_client.delete_agent_runtime(\n",
    "            agentRuntimeId=agent_runtime_id\n",
    "        )\n",
    "        print(f\"Initiated deletion of AgentCore Runtime: {agent_runtime_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting AgentCore Runtime: {agent_runtime_id}\")\n",
    "    \n",
    "    # Delete the ECR repository\n",
    "    try:\n",
    "        ecr_client = boto3.client('ecr')\n",
    "        ecr_client.delete_repository(\n",
    "            repositoryName=repository_name,\n",
    "            force=True  # Force deletion even if it contains images\n",
    "        )\n",
    "        print(f\"Deleted ECR repository: {repository_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting ECR repository: {repository_name}\")\n",
    "    \n",
    "    # Remove the Dockerfile\n",
    "    try:\n",
    "        if os.path.exists('Dockerfile'):\n",
    "            os.remove('Dockerfile')\n",
    "            print(\"Deleted Dockerfile\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting Dockerfile\")\n",
    "\n",
    "# Uncomment the line below to clean up resources\n",
    "# cleanup_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated how to:\n",
    "\n",
    "1. Package the agent into a Docker container\n",
    "2. Deploy the agent to AgentCore Runtime using direct boto3 API calls\n",
    "3. Test the deployed agent using AgentCore Runtime Endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}